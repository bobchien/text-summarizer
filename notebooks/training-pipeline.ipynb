{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "swymtxpl7W7w",
    "tags": []
   },
   "source": [
    "## <b> Setup <b/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### <b> Colab <b/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Mar  3 16:49:37 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.103.01   Driver Version: 470.103.01   CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:07:00.0  On |                  N/A |\n",
      "|  0%   53C    P3    35W / 170W |    865MiB / 12052MiB |      1%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "colab = False\n",
    "\n",
    "if colab:\n",
    "    \n",
    "    PROJECT_NAME = ''\n",
    "    if colab & (PROJECT_NAME==''): raise ValueError('Please modify PROJECT_NAME for running on Colab')\n",
    "    \n",
    "    ### Access Google Drive\n",
    "\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "\n",
    "    ### Access GCS\n",
    "\n",
    "    from google.colab import auth\n",
    "    auth.authenticate_user()\n",
    "\n",
    "    ### Mount the directories\n",
    "\n",
    "    import os\n",
    "\n",
    "    # Mount the data directory\n",
    "    os.chdir(f'/content/gdrive/MyDrive/LinuxServer-Bob/Code/Project/{PROJECT_NAME}/src')\n",
    "    os.symlink('/content/gdrive/MyDrive/LinuxServer-Bob/Data', '/data')\n",
    "    print(f\"PWD: {os.getcwd()}\")\n",
    "\n",
    "    # Mount the tfrecord directory\n",
    "    gcs_path = \"gs://bobscchien-project-data\"\n",
    "\n",
    "    ### Install packages\n",
    "\n",
    "    !pip3 install -r '../requirements.txt'\n",
    "\n",
    "\n",
    "### Check the computation resources\n",
    "\n",
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "    print('Not connected to a GPU')\n",
    "else:\n",
    "    print(gpu_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### <b> Initialization <b/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory /data/Model_Tensorflow exists.\n",
      "Directory /data/Model_Pytorch exists.\n",
      "Directory ../models/tokenizers exists.\n",
      "Directory /data/Text_Summarizer/data exists.\n",
      "Directory /data/Text_Summarizer/models exists.\n",
      "Directory ../models/tokenizers/data/vocab exists.\n",
      "Directory ../models/tokenizers/models/trained exists.\n",
      "Directory /data/Text_Summarizer/data/raw exists.\n",
      "Directory /data/Text_Summarizer/data/intermin exists.\n",
      "Directory /data/Text_Summarizer/data/processed exists.\n",
      "Directory /data/Text_Summarizer/models/savedmodels exists.\n",
      "Directory /data/Text_Summarizer/models/checkpoints exists.\n",
      "Directory /data/Text_Summarizer/models/logs exists.\n",
      "\n",
      "Running on GPU...\n",
      "\n",
      "Your runtime has 101.1 gigabytes of available RAM\n",
      "\n",
      "You are using a high-RAM runtime!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-03 16:49:40.384709: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-03 16:49:40.391385: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-03 16:49:40.392106: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-03 16:49:40.393239: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-03-03 16:49:40.393652: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-03 16:49:40.394046: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-03 16:49:40.394515: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-03 16:49:40.752282: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-03 16:49:40.752654: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-03 16:49:40.752967: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-03 16:49:40.753262: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9374 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:07:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "### setup parent directory path \n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append('..')\n",
    "sys.path.append('../src')\n",
    "\n",
    "### initialization\n",
    "\n",
    "from utils.initialization import *\n",
    "\n",
    "if colab:\n",
    "    DIR_VOCAB       = os.path.join(gcs_path, 'Text_Tokenizer', 'vocab')\n",
    "    DIR_TOKEN       = os.path.join(gcs_path, 'Text_Tokenizer', 'trained')\n",
    "\n",
    "    DIR_TFRECORD    = os.path.join(gcs_path, PROJECT_NAME, 'data', 'processed')\n",
    "    DIR_MODEL       = os.path.join(gcs_path, PROJECT_NAME, 'models', 'savedmodels')\n",
    "    DIR_CHECKPOINT  = os.path.join(gcs_path, PROJECT_NAME, 'models', 'checkpoints')\n",
    "    DIR_LOG         = os.path.join(gcs_path, PROJECT_NAME, 'models', 'logs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-cCvXbPkccV1",
    "tags": []
   },
   "source": [
    "## <b> 1. Load Dataset <b/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training Data : 389998\n",
      "Number of Validation Data : 5000\n",
      "Number of Testing Data : 5000\n",
      "\n",
      "Review: 週六，兩對極其熱愛培根的夫婦共同在愛荷華州的ｄｅｓｍｏｉｎｅｓ舉辦了婚禮，婚禮以培根為主題，宣誓時雙方均表示，要與愛人共享“美好時光和培根”。婚禮在當地的“藍絲帶培根節”當天舉辦，許多前來參加培根節的人也前來參加。\n",
      "\n",
      "Label : 愛你就像愛培根！美國兩對吃貨共同舉辦培根婚禮\n",
      "\n",
      " ==================================================\n",
      "\n",
      "Review: 民主開言路，協商凝共識。人民政協作為中國人民愛國統一戰線的組織、中國共產黨領導的多黨合作和政治協商的重要機構、我國政治生活中發揚社會主義民主的重要形式，是各黨派團體和各族各界人士發揚民主、參與國是、團結合作的重要平臺。\n",
      "\n",
      "Label : 民主廣開言路協商凝聚共識\n",
      "\n",
      " ==================================================\n",
      "\n",
      "Review: 中央紀委監察部網站１７日訊息，經查，丁寶軍利用職務上的便利為他人謀取利益，收受賄賂，數額巨大；收受禮金；與一名女性長期保持不正當兩性關係。決定給予丁寶軍開除黨籍處分，並按規定依法辦理開除公職手續。\n",
      "\n",
      "Label : 安徽省煤田地質局原副局長丁寶軍被開除黨籍\n",
      "\n",
      " ==================================================\n",
      "\n",
      "Review: 當都市麗人董事長鄭耀南牽著志玲姐姐在推介會上宣佈從６月１６日起招股募資近１８億港元，都市麗人２６日將在聯交所主機板掛牌上市時。這位保安出身、從賣襪子、賣文胸起家的農家少年終於華麗的成功逆襲為高富帥。\n",
      "\n",
      "Label : 林志玲為內衣股都市麗人造勢赴港認購遇冷\n",
      "\n",
      " ==================================================\n",
      "\n",
      "Review: 一方面，是民間投資渠道的匱乏，一方面，是打著高收益旗號的投資公司。當這類機構如雨後春筍般不斷冒出的時候，利益驅動也使得普通市民在知情或不知情的前提下成為其中一環。即使風險已經暴露，但身在其中難以退出的現實也成為一大阻礙。\n",
      "\n",
      "Label : 民間借貸擊鼓傳花花砸誰家\n",
      "\n",
      " ==================================================\n",
      "\n",
      "Review: 僅一年光景，就有４２名涉貪涉腐的省部級高官落馬，中紀委當之無愧地成為全中國最受關注的“有關部門”。近日，中紀委網站公佈了一個“驚人”的資料，該網站全年的點選量已經超過９．７億次！若換算成廣告投放相當於４８５萬元。\n",
      "\n",
      "Label : ２０１４年中紀委網站點選量破９．７億若投放廣告估價４８５萬\n",
      "\n",
      " ==================================================\n",
      "\n",
      "Review: １１月１９日劉豔從幼兒園接小毛回家發現他臉上有紅掌印，就詢問班主任，當時老師說，孩子臉上的掌印是和同學打鬧留下的…但覺得孩子臉上的掌印有些大，不像是孩子留下的。我在班上和小朋友玩，被一個保安叔叔打了，還流鼻血了。\n",
      "\n",
      "Label : 烏魯木齊一幼兒園孩子打鬧遭保安扇耳光！\n",
      "\n",
      " ==================================================\n",
      "\n",
      "Review: 一個１０歲的孩子唱《好久不見》走紅，唱到動情處神情憂鬱哀怨，被稱作“憂鬱弟”；５歲的孩子用稚嫩的聲音唱《因為愛情》，被網友贊“可愛”。兒童當然要聽兒童歌曲，實際上，許多兒童更偏愛和大人們聽“同一首歌”，甚至從小開始唱《因為愛情》。\n",
      "\n",
      "Label : 兒童愛唱大人的歌\n",
      "\n",
      " ==================================================\n",
      "\n",
      "Review: 當地時間７月２１日，哈布沙暴席捲美國鳳凰城，碧藍的天空頓時頓時變成了暗紅色。哈布沙暴在阿拉伯語中就是大規模沙塵暴的意思。據美國官方天氣報告顯示，此次沙暴高度約為６００米，造成鳳凰城機場封閉２０分鐘，有關部門沒有收到人員傷亡報告。\n",
      "\n",
      "Label : 沙暴席捲美國鳳凰城場面如臨末日\n",
      "\n",
      " ==================================================\n",
      "\n",
      "Review: 文雙春：從根本上看，一份好的學術刊物必然要跨越國籍和語種。一國或一地的學術評價機制作為一種外部的人為因素，合理與否都很難影響它的學術品質，也很難撼動它的學術地位。不但要千方百計留住國內優秀稿件，更要想方設法吸引國外優秀稿件。\n",
      "\n",
      "Label : 究竟拿什麼來留住國內優秀稿件？\n",
      "\n",
      " ==================================================\n",
      "\n",
      "Review: 來自湖南的小杰跟隨父母在溫州生活。上週，他不慎墜樓，腦部受傷嚴重，救治無望。父母毅然決定捐獻小杰的器官。１３日，他的肝臟、腎臟被連夜送往杭州，拯救２個大人１個孩子。眼角膜則留在溫州，留給需要的病人。\n",
      "\n",
      "Label : 用另一種方式活著\n",
      "\n",
      " ==================================================\n",
      "\n",
      "Review: 兩三萬人擠一班公交！因公交線路少，致鄭州龍子湖東大學城河南理工萬方科技學院等周邊學校學生出行困難。昨日，交通委做出回覆：１，對５７０路班次進行加密，週末達到１５０次，若有需要還會增加；２，還計劃新開通一條公交線路。\n",
      "\n",
      "Label : 鄭州龍子湖大學城的學生們，這有好訊息！\n",
      "\n",
      " ==================================================\n",
      "\n",
      "Review: 根據中原地產市場研究部的統計資料，截至６月２０日，北京樓市庫存為８０８４４套，這是２０１３年初庫存跌下８萬套後，再次迴歸８萬套以上。住宅房屋庫存數量創下近１８個月的新高。\n",
      "\n",
      "Label : 北京住宅庫存再次突破８萬套，創１８個月新高\n",
      "\n",
      " ==================================================\n",
      "\n",
      "Review: 昨日早晨６時５５分，北湖北路１８號南寧市機械施工公司生活區裡的路面突然發生塌陷，緊挨著旁邊的是一樓盤的施工工地。２分多鐘後塌陷路面形成一個深達１０多米的深坑，所無人員傷亡。距離塌陷路面最近的５６戶居民已經得到妥善安置。\n",
      "\n",
      "Label : 兩分多鐘路面塌陷１０米深坑北湖北路５６戶居民撤離\n",
      "\n",
      " ==================================================\n",
      "\n",
      "Review: 一隻騎在蝸牛背上的螳螂。一隻新生的螳螂騎在蝸牛背上穿過叢林。這隻螳螂被雨水打下樹葉並掉到水坑裡，所幸它設法爬上了途經的蝸牛背上，“搭車”到達安全的地方。攝影師ｎｏｒｄｉｎｓｅｒｕｙａｎ捕捉到這一精彩瞬間。\n",
      "\n",
      "Label : 碉堡了！機靈小螳螂～騎著蝸牛穿過叢林！\n",
      "\n",
      " ==================================================\n",
      "\n",
      "Review: 俗話說“秋瓜壞肚”，立秋之後不論是西瓜還是香瓜、菜瓜都不能多吃，否則會損傷脾胃的陽氣。秋季本來就是腹瀉高發季節，若此時再大量食用西瓜等寒性水果很容易拉肚子，孩子更要少吃。立秋後養生要以防“秋燥”為主，可多吃蘋果、梨、葡萄等滋陰的水果。\n",
      "\n",
      "Label : 處暑已過秋瓜少吃\n",
      "\n",
      " ==================================================\n",
      "\n",
      "Review: 今年夏天對於英國皇室來說真是喜事不斷，在凱特王妃不久前順利誕下一子之後，她的妹妹皮帕－米德爾頓（ｐｉｐｐａｍｉｄｄｌｅｔｏｗｎ）似乎也“好事將近”。據傳，皮帕已經與銀行家男友尼克－傑克遜訂婚數月，婚禮擬將於明年春天舉辦\n",
      "\n",
      "Label : 傳凱特王妃之妹已與銀行家男友祕密訂婚\n",
      "\n",
      " ==================================================\n",
      "\n",
      "Review: ２０１４年夏天，一篇揭露創投圈怪現狀的文章被傳得特別火，裡面提到一個曾是“著名站長”的天使投資人只能靠給創業者算星座來投專案。這說的不就是戴志康嗎？僅從表面看，戴志康符合傳言中的落魄形象。他本是中國最著名的站長之一，當年８０後．．\n",
      "\n",
      "Label : 戴志康：離開騰訊做天使損失７０００萬\n",
      "\n",
      " ==================================================\n",
      "\n",
      "Review: ９塊錢，能買什麼？３袋方便麵，半雙絲襪，以及看病時找個專家。修理電腦也不至於這麼便宜，修理身體卻如此廉價，合理嗎？專家號掛號費過低，除了影響醫生合理收入，起碼還有三樣壞處：紅包屢禁不止、小病佔大資源、養肥票販子。\n",
      "\n",
      "Label : 人民日報：醫院專家掛號費９元過低只能買半雙絲襪\n",
      "\n",
      " ==================================================\n",
      "\n",
      "Review: 無論從衛生、環保、便捷等多因素考慮，自己動手現磨豆漿都將是不二選擇。現在市面上的品牌也很多，比如九陽豆漿機、蘇泊爾豆漿機、美的豆漿機等。而豆漿機也成為各大廚具展上的常客，吸“睛”無數\n",
      "\n",
      "Label : 老石磨豆漿機成廚具展上常客吸人眼球\n",
      "\n",
      " ==================================================\n"
     ]
    }
   ],
   "source": [
    "from make_dataset import *\n",
    "\n",
    "train_texts, train_labels = pd.read_csv(os.path.join(DIR_INTERMIN, lang, 'train.zip'))[['source', 'target']].dropna().values.T.tolist()\n",
    "valid_texts, valid_labels = pd.read_csv(os.path.join(DIR_INTERMIN, lang, 'valid.zip'))[['source', 'target']].dropna().values.T.tolist()\n",
    "test_texts, test_labels = pd.read_csv(os.path.join(DIR_INTERMIN, lang, 'test.zip'))[['source', 'target']].dropna().values.T.tolist()\n",
    "\n",
    "### demo\n",
    "\n",
    "for name, data in zip(['Training', 'Validation', 'Testing'], [train_texts, valid_texts, test_texts]):\n",
    "    print(f\"Number of {name} Data :\", len(data))\n",
    "    \n",
    "for text, label in zip(test_texts[-20:], test_labels[-20:]):\n",
    "    print(f'\\nReview: {text}')\n",
    "    print(f'\\nLabel : {label}')\n",
    "    print('\\n', '=' * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fd1NWMxjfsDd",
    "tags": []
   },
   "source": [
    "## <b> 2. Load Tokenizer & TFRecord <b/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using Pretrained Bert Model: {'inp': 'ckiplab/albert-tiny-chinese', 'tar': None}\n",
      "Cache Directory of Model: {'inp': '/data/Model_Pytorch/ckiplab/albert-tiny-chinese', 'tar': None}\n",
      "\n",
      "Max Length of Text: {'inp': 256, 'tar': 64}\n",
      "zh Vocabulary Size : 21128\n",
      "zh Vocabulary Size : 10362\n",
      "((<tf.Tensor: shape=(64, 137), dtype=int32, numpy=\n",
      "array([[ 101, 4245, 7621, ...,    0,    0,    0],\n",
      "       [ 101, 3791, 1751, ...,    0,    0,    0],\n",
      "       [ 101, 8029, 3299, ...,    0,    0,    0],\n",
      "       ...,\n",
      "       [ 101, 7442, 3975, ...,    0,    0,    0],\n",
      "       [ 101, 8034, 3299, ...,    0,    0,    0],\n",
      "       [ 101, 8029,  510, ...,    0,    0,    0]], dtype=int32)>, <tf.Tensor: shape=(64, 137), dtype=int32, numpy=\n",
      "array([[1, 1, 1, ..., 0, 0, 0],\n",
      "       [1, 1, 1, ..., 0, 0, 0],\n",
      "       [1, 1, 1, ..., 0, 0, 0],\n",
      "       ...,\n",
      "       [1, 1, 1, ..., 0, 0, 0],\n",
      "       [1, 1, 1, ..., 0, 0, 0],\n",
      "       [1, 1, 1, ..., 0, 0, 0]], dtype=int32)>), <tf.Tensor: shape=(64, 32), dtype=int32, numpy=\n",
      "array([[  2, 357, 628, ...,   0,   0,   0],\n",
      "       [  2, 100, 467, ...,   0,   0,   0],\n",
      "       [  2, 495, 276, ...,   0,   0,   0],\n",
      "       ...,\n",
      "       [  2, 820, 871, ...,   0,   0,   0],\n",
      "       [  2, 560, 200, ...,   0,   0,   0],\n",
      "       [  2, 605, 460, ...,   0,   0,   0]], dtype=int32)>)\n"
     ]
    }
   ],
   "source": [
    "from make_tfrecord import *\n",
    "\n",
    "# setup dataset parameters\n",
    "BUFFER_SIZE = 400000\n",
    "BATCH_SIZE = 64\n",
    "GLOBAL_BATCH_SIZE = BATCH_SIZE * strategy.num_replicas_in_sync\n",
    "\n",
    "# load tfrecord\n",
    "train_batches = loadTFRecord('train', os.path.join(DIR_TFRECORD, lang), GLOBAL_BATCH_SIZE, BUFFER_SIZE)\n",
    "valid_batches = loadTFRecord('valid', os.path.join(DIR_TFRECORD, lang), GLOBAL_BATCH_SIZE)\n",
    "test_batches = loadTFRecord('test',   os.path.join(DIR_TFRECORD, lang), GLOBAL_BATCH_SIZE, cache=False)\n",
    "\n",
    "for demo in test_batches.take(1):\n",
    "    print(demo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <b> 3. Model Training & Evaluation <b/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b> Modeling <b/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " {'predictions': Value(dtype='string', id='sequence'), 'references': Value(dtype='string', id='sequence')}\n",
      "\n",
      "Number of Samples: 389992\n",
      "\n",
      "warmup_steps: 60940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-03 16:50:05.492434: I tensorflow/stream_executor/cuda/cuda_blas.cc:1774] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFAlbertModel: ['predictions.LayerNorm.weight', 'predictions.bias', 'predictions.dense.bias', 'predictions.decoder.weight', 'predictions.decoder.bias', 'predictions.dense.weight', 'albert.embeddings.position_ids', 'predictions.LayerNorm.bias']\n",
      "- This IS expected if you are initializing TFAlbertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFAlbertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFAlbertModel were not initialized from the PyTorch model and are newly initialized: ['albert.pooler.weight', 'albert.pooler.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_ids (InputLayer)         [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " attention_mask (InputLayer)    [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " tf_albert_model (TFAlbertModel  TFBaseModelOutputWi  4080520    ['input_ids[0][0]',              \n",
      " )                              thPooling(last_hidd               'attention_mask[0][0]']         \n",
      "                                en_state=(None, Non                                               \n",
      "                                e, 312),                                                          \n",
      "                                 pooler_output=(Non                                               \n",
      "                                e, 312),                                                          \n",
      "                                 hidden_states=None                                               \n",
      "                                , attentions=None)                                                \n",
      "                                                                                                  \n",
      " embedding_projector (Embedding  (None, None, 256)   146432      ['tf_albert_model[1][0]']        \n",
      " Projector)                                                                                       \n",
      "                                                                                                  \n",
      " target_ids (InputLayer)        [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " transformer_encoder (Transform  ((None, None, 256),  8941568    ['embedding_projector[1][0]',    \n",
      " erEncoder)                      (None, 1, None))                 'attention_mask[0][0]']         \n",
      "                                                                                                  \n",
      " transformer_decoder (Transform  ((None, None, 256),  54787072   ['target_ids[0][0]',             \n",
      " erDecoder)                      {'decoder_layer1_b               'transformer_encoder[1][0]',    \n",
      "                                lock1': (None, 16,                'transformer_encoder[1][1]']    \n",
      "                                None, None),                                                      \n",
      "                                 'decoder_layer1_bl                                               \n",
      "                                ock2': (None, 16, N                                               \n",
      "                                one, None),                                                       \n",
      "                                 'decoder_layer2_bl                                               \n",
      "                                ock1': (None, 16, N                                               \n",
      "                                one, None),                                                       \n",
      "                                 'decoder_layer2_bl                                               \n",
      "                                ock2': (None, 16, N                                               \n",
      "                                one, None),                                                       \n",
      "                                 'decoder_layer3_bl                                               \n",
      "                                ock1': (None, 16, N                                               \n",
      "                                one, None),                                                       \n",
      "                                 'decoder_layer3_bl                                               \n",
      "                                ock2': (None, 16, N                                               \n",
      "                                one, None),                                                       \n",
      "                                 'decoder_layer4_bl                                               \n",
      "                                ock1': (None, 16, N                                               \n",
      "                                one, None),                                                       \n",
      "                                 'decoder_layer4_bl                                               \n",
      "                                ock2': (None, 16, N                                               \n",
      "                                one, None),                                                       \n",
      "                                 'decoder_layer5_bl                                               \n",
      "                                ock1': (None, 16, N                                               \n",
      "                                one, None),                                                       \n",
      "                                 'decoder_layer5_bl                                               \n",
      "                                ock2': (None, 16, N                                               \n",
      "                                one, None),                                                       \n",
      "                                 'decoder_layer6_bl                                               \n",
      "                                ock1': (None, 16, N                                               \n",
      "                                one, None),                                                       \n",
      "                                 'decoder_layer6_bl                                               \n",
      "                                ock2': (None, 16, N                                               \n",
      "                                one, None)})                                                      \n",
      "                                                                                                  \n",
      " dense_18 (Dense)               (None, None, 10362)  2663034     ['transformer_decoder[1][0]']    \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 70,618,626\n",
      "Trainable params: 66,538,106\n",
      "Non-trainable params: 4,080,520\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      " None\n",
      "\n",
      "Model Name: ZH_BertEncoderTransformer_ckiplab-albert-tiny-chinese\n",
      "\n",
      "run_id: 2-6layers_1projlayers_tune0layers_16heads_256embed_512hidden_embedpos_0.2dropout_gelu_10362tarvocab_0.0005initlr_60940warmup_AdamWeightDecay_64batchsize_400000shuffle_389992samples_100%Teacher \n",
      "\n",
      "There is no existed checkpoint ... Start from the beginning.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from model_training import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b> Training <b/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if colab:\n",
    "    %load_ext tensorboard\n",
    "    %tensorboard --logdir {DIR_LOG}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "6094/6094 [==============================] - ETA: 0s - loss: 6.6790 - accuracy: 0.1071\n",
      "    Input: 營 養 改 善 計 劃 啟 動 之 初 ， 公 眾 和 輿 論 就 已 準 確 預 估 了 將 來 可 能 出 現 的 問 題 。 須 防 貪 腐 之 手 ， 要 清 除 利 益 鏈 條 ， 微 博 時 代 ， 一 定 要 形 成 公 開 、 透 明 、 及 時 、 高 效 的 社 會 監 督 互 動 模 式 ， 時 至 今 日 ， 回 想 這 種 驚 人 的 預 見 性 實 讓 人 五 味 雜 陳 。\n",
      "    Target: 級 協 父 立 沒 析 機 有 反 球 稱 [UNK]\n",
      "    Predict: 到 傳 到 傳 到 傳 到 傳 到 最\n",
      "\n",
      "    Input: ５７ 歲 的 法 國 人 阿 蘭 － 佩 林 將 成 國 足 新 帥 ， 率 領 男 足 衝 擊 ２０１５ 年 亞 洲 盃 。 佩 林 長 期 在 西 亞 海 灣 執 教 ， 熟 悉 和 了 解 亞 洲 足 球 。 據 悉 年 薪 在 １００ 萬 美 元 以 內 。 他 預 計 在 明 天 抵 達 清 遠 與 國 足 會 合 ， 然 後 隨 隊 前 往 迪 拜 備 戰 與 伊 拉 克 亞 預 賽 。\n",
      "    Target: 人 養 來 與 繁 [UNK] 作 人 些 翻 根 早 [UNK] 摔 停\n",
      "    Predict: 現 人 [UNK] 在 [UNK] [UNK] [UNK] 名 現 人 [UNK] 名 現 ７\n",
      "\n",
      "    Input: 法 國 知 名 報 紙 《 世 界 報 》 日 前 宣 稱 ， 法 國 情 報 部 門 對 外 安 全 總 局 也 正 在 執 行 類 似 專 案 ， 即 監 聽 民 眾 的 電 子 通 訊 資 料 。 《 世 界 報 》 稱 ， 對 外 安 全 總 局 擁 有 巨 大 的 電 子 監 聽 體 系 ， 收 集 電 腦 和 手 機 的 資 料 資 訊 ， 監 控 法 國 國 內 及 對 外 的 通 訊 活 動 。\n",
      "    Target: 作 ｙ 承 給 作 人 察 鰲 珠 十 度\n",
      "    Predict: 作 人 內 管 內 管 到 最 內 管 合\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 5.23706, saving model to /data/Text_Summarizer/models/checkpoints/ZH_BertEncoderTransformer_ckiplab-albert-tiny-chinese_2-6layers_1projlayers_tune0layers_16heads_256embed_512hidden_embedpos_0.2dropout_gelu_10362tarvocab_0.0005initlr_60940warmup_AdamWeightDecay_64batchsize_400000shuffle_389992samples_100%Teacher/ckpt\n",
      "6094/6094 [==============================] - 3585s 586ms/step - loss: 6.6790 - accuracy: 0.1071 - val_loss: 5.2371 - val_accuracy: 0.1956\n",
      "Epoch 2/100\n",
      " 618/6094 [==>...........................] - ETA: 52:24 - loss: 5.2549 - accuracy: 0.1965"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "history = model.fit(train_batches.repeat(EPOCHS), validation_data=valid_batches,\n",
    "                    initial_epoch=last_epoch, epochs=EPOCHS, steps_per_epoch=steps_per_epoch, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4531/4531 [==============================] - ETA: 0s - loss: 6.9379 - accuracy: 0.0786\n",
      "    Input: 近 日 ， 有 網 友 反 映 ， 黑 龍 江 移 動 公 司 疑 似 私 自 為 客 戶 套 送 增 值 付 費 套 餐 ， 這 些 業 務 並 沒 有 經 過 客 戶 的 主 觀 同 意 。 舉 報 問 題 的 網 友 認 為 ， 其 個 人 資 訊 的 安 全 受 到 了 嚴 重 威 脅 。 對 此 ， 移 動 公 司 表 示 正 在 調 查 ， 並 將 於 14 日 給 出 回 覆 。\n",
      "    Target: 中 移 動 被 爆 私 自 增 減 客 戶 業 務 迴 應 稱 正 調 查\n",
      "    Predict: 廣 州 [UNK] 年 [UNK] 個 月 [UNK] 萬\n",
      "\n",
      "    Input: 截 至 2013 年 9 月 30 日 的 六 個 月 裡 ， 銷 售 收 入 617 億 日 元 ( 6. 26 億 美 元 ) ， 同 比 增 長 1 % 。 然 而 淨 收 入 方 面 的 增 長 更 為 突 出 ， 去 年 同 期 該 公 司 還 處 於 虧 損 狀 態 ， 而 今 年 則 從 原 來 的 55 億 日 元 ( 5600 萬 美 元 ) 虧 損 轉 成 了 26 億 日 元 ( 2600 萬 美 元 ) 的 盈 利 。\n",
      "    Target: 扭 虧 為 盈 [UNK] 上 半 財 年 收 6 . [UNK] 億 美 元\n",
      "    Predict: [UNK] 億 美 元 [UNK] 億 美 元\n",
      "\n",
      "    Input: 網 際 網 路 對 裝 修 使 用 者 的 影 響 ， 造 就 了 網 際 網 路 對 家 居 行 業 的 影 響 。 齊 家 網 做 了 很 多 工 作 。 主 要 分 成 兩 部 分 ： 一 部 分 圍 繞 網 際 網 路 思 維 ， 把 體 驗 、 極 致 、 創 新 做 透 。 第 二 部 分 圍 繞 著 家 居 ， 通 過 團 購 、 商 城 、 體 驗 館 形 成 了 齊 家 2 模 式 。\n",
      "    Target: 2 案 例 : 齊 家 如 何 應 對 2 帶 來 的 家 居 變 革\n",
      "    Predict: 網 路 網 路 網 路 網 路 網 路 網 路\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 5.69249, saving model to /data/Text_Summarizer/models/checkpoints/ZH_BertEncoderTransformer_ckiplab-albert-tiny-chinese_2-6layers_1projlayers_tune0layers_8heads_256embed_512hidden_0.2dropout_gelu_9230tarvocab_0.0005initlr_45310warmup_AdamWeightDecay_64batchsize_8192shuffle_289936samples_100%Teacher/ckpt\n",
      "4531/4531 [==============================] - 1464s 321ms/step - loss: 6.9379 - accuracy: 0.0786 - val_loss: 5.6925 - val_accuracy: 0.1522\n",
      "Epoch 2/100\n",
      "4531/4531 [==============================] - ETA: 0s - loss: 5.0342 - accuracy: 0.2221\n",
      "    Input: 近 日 ， 有 網 友 反 映 ， 黑 龍 江 移 動 公 司 疑 似 私 自 為 客 戶 套 送 增 值 付 費 套 餐 ， 這 些 業 務 並 沒 有 經 過 客 戶 的 主 觀 同 意 。 舉 報 問 題 的 網 友 認 為 ， 其 個 人 資 訊 的 安 全 受 到 了 嚴 重 威 脅 。 對 此 ， 移 動 公 司 表 示 正 在 調 查 ， 並 將 於 14 日 給 出 回 覆 。\n",
      "    Target: 中 移 動 被 爆 私 自 增 減 客 戶 業 務 迴 應 稱 正 調 查\n",
      "    Predict: 黑 龍 江 移 動 公 司 服 務 服 務\n",
      "\n",
      "    Input: 網 際 網 路 對 裝 修 使 用 者 的 影 響 ， 造 就 了 網 際 網 路 對 家 居 行 業 的 影 響 。 齊 家 網 做 了 很 多 工 作 。 主 要 分 成 兩 部 分 ： 一 部 分 圍 繞 網 際 網 路 思 維 ， 把 體 驗 、 極 致 、 創 新 做 透 。 第 二 部 分 圍 繞 著 家 居 ， 通 過 團 購 、 商 城 、 體 驗 館 形 成 了 齊 家 2 模 式 。\n",
      "    Target: 2 案 例 : 齊 家 如 何 應 對 2 帶 來 的 家 居 變 革\n",
      "    Predict: 網 際 網 路 網 路 網 際 網 路 網 路\n",
      "\n",
      "    Input: 最 近 ， 一 款 名 為 雷 達 - 密 碼 破 解 器 的 蹭 網 神 器 在 街 頭 攤 點 上 時 有 出 現 。 商 家 叫 賣 稱 1 其 可 以 獲 取 周 邊 電 腦 網 路 的 - 熱 點 資 訊 ， 並 自 動 破 解 密 碼 ， 終 身 不 用 付 網 費 。 它 其 實 是 一 個 用 供 電 的 的 發 光 二 極 體 。\n",
      "    Target: 榕 街 頭 現 - 密 碼 破 解 器 實 為 地 攤 騙 錢 神 器\n",
      "    Predict: 網 際 網 路 網 路 電 腦 器\n",
      "\n",
      "Epoch 00002: val_loss improved from 5.69249 to 4.34456, saving model to /data/Text_Summarizer/models/checkpoints/ZH_BertEncoderTransformer_ckiplab-albert-tiny-chinese_2-6layers_1projlayers_tune0layers_8heads_256embed_512hidden_0.2dropout_gelu_9230tarvocab_0.0005initlr_45310warmup_AdamWeightDecay_64batchsize_8192shuffle_289936samples_100%Teacher/ckpt\n",
      "4531/4531 [==============================] - 1451s 320ms/step - loss: 5.0342 - accuracy: 0.2221 - val_loss: 4.3446 - val_accuracy: 0.2980\n",
      "Epoch 3/100\n",
      "4531/4531 [==============================] - ETA: 0s - loss: 4.0831 - accuracy: 0.3328\n",
      "    Input: 近 日 ， 有 網 友 反 映 ， 黑 龍 江 移 動 公 司 疑 似 私 自 為 客 戶 套 送 增 值 付 費 套 餐 ， 這 些 業 務 並 沒 有 經 過 客 戶 的 主 觀 同 意 。 舉 報 問 題 的 網 友 認 為 ， 其 個 人 資 訊 的 安 全 受 到 了 嚴 重 威 脅 。 對 此 ， 移 動 公 司 表 示 正 在 調 查 ， 並 將 於 14 日 給 出 回 覆 。\n",
      "    Target: 中 移 動 被 爆 私 自 增 減 客 戶 業 務 迴 應 稱 正 調 查\n",
      "    Predict: 黑 龍 江 移 動 服 務 服 務 調 查\n",
      "\n",
      "    Input: 截 至 2013 年 9 月 30 日 的 六 個 月 裡 ， 銷 售 收 入 617 億 日 元 ( 6. 26 億 美 元 ) ， 同 比 增 長 1 % 。 然 而 淨 收 入 方 面 的 增 長 更 為 突 出 ， 去 年 同 期 該 公 司 還 處 於 虧 損 狀 態 ， 而 今 年 則 從 原 來 的 55 億 日 元 ( 5600 萬 美 元 ) 虧 損 轉 成 了 26 億 日 元 ( 2600 萬 美 元 ) 的 盈 利 。\n",
      "    Target: 扭 虧 為 盈 [UNK] 上 半 財 年 收 6 . [UNK] 億 美 元\n",
      "    Predict: 淨 收 入 [UNK] 億 美 元 同 比 增 長 [UNK] . [UNK] 億 美 元\n",
      "\n",
      "    Input: 網 際 網 路 對 裝 修 使 用 者 的 影 響 ， 造 就 了 網 際 網 路 對 家 居 行 業 的 影 響 。 齊 家 網 做 了 很 多 工 作 。 主 要 分 成 兩 部 分 ： 一 部 分 圍 繞 網 際 網 路 思 維 ， 把 體 驗 、 極 致 、 創 新 做 透 。 第 二 部 分 圍 繞 著 家 居 ， 通 過 團 購 、 商 城 、 體 驗 館 形 成 了 齊 家 2 模 式 。\n",
      "    Target: 2 案 例 : 齊 家 如 何 應 對 2 帶 來 的 家 居 變 革\n",
      "    Predict: 網 際 網 路 裝 修 使 用 者 體 驗 館\n",
      "\n",
      "Epoch 00003: val_loss improved from 4.34456 to 3.57337, saving model to /data/Text_Summarizer/models/checkpoints/ZH_BertEncoderTransformer_ckiplab-albert-tiny-chinese_2-6layers_1projlayers_tune0layers_8heads_256embed_512hidden_0.2dropout_gelu_9230tarvocab_0.0005initlr_45310warmup_AdamWeightDecay_64batchsize_8192shuffle_289936samples_100%Teacher/ckpt\n",
      "4531/4531 [==============================] - 1450s 320ms/step - loss: 4.0831 - accuracy: 0.3328 - val_loss: 3.5734 - val_accuracy: 0.4067\n",
      "Epoch 4/100\n",
      "4531/4531 [==============================] - ETA: 0s - loss: 3.4891 - accuracy: 0.4141\n",
      "    Input: 近 日 ， 有 網 友 反 映 ， 黑 龍 江 移 動 公 司 疑 似 私 自 為 客 戶 套 送 增 值 付 費 套 餐 ， 這 些 業 務 並 沒 有 經 過 客 戶 的 主 觀 同 意 。 舉 報 問 題 的 網 友 認 為 ， 其 個 人 資 訊 的 安 全 受 到 了 嚴 重 威 脅 。 對 此 ， 移 動 公 司 表 示 正 在 調 查 ， 並 將 於 14 日 給 出 回 覆 。\n",
      "    Target: 中 移 動 被 爆 私 自 增 減 客 戶 業 務 迴 應 稱 正 調 查\n",
      "    Predict: 黑 龍 江 移 動 公 司 否 認 為 客 戶 套 送 套 餐\n",
      "\n",
      "    Input: 網 際 網 路 對 裝 修 使 用 者 的 影 響 ， 造 就 了 網 際 網 路 對 家 居 行 業 的 影 響 。 齊 家 網 做 了 很 多 工 作 。 主 要 分 成 兩 部 分 ： 一 部 分 圍 繞 網 際 網 路 思 維 ， 把 體 驗 、 極 致 、 創 新 做 透 。 第 二 部 分 圍 繞 著 家 居 ， 通 過 團 購 、 商 城 、 體 驗 館 形 成 了 齊 家 2 模 式 。\n",
      "    Target: 2 案 例 : 齊 家 如 何 應 對 2 帶 來 的 家 居 變 革\n",
      "    Predict: 齊 家 2 : 網 際 網 路 思 維\n",
      "\n",
      "    Input: 最 近 ， 西 安 市 接 連 發 生 兩 起 因 村 民 加 蓋 民 房 而 造 成 的 傷 亡 事 件 ， 共 造 成 3 人 死 亡 ， 其 中 一 名 是 隻 有 5 個 月 大 的 嬰 兒 。 可 在 血 的 教 訓 下 ， 該 市 高 新 區 的 南 窯 頭 村 加 蓋 行 為 依 然 瘋 狂 。 據 瞭 解 ， 村 民 加 蓋 是 為 了 出 租 房 子 牟 利 。\n",
      "    Target: 西 安 城 中 村 加 蓋 兩 天 奪 3 命 加 蓋 仍 在 瘋 狂 上 演\n",
      "    Predict: 西 安 一 村 民 加 蓋 民 房 致 3 死 3 人 死 亡\n",
      "\n",
      "Epoch 00004: val_loss improved from 3.57337 to 3.22140, saving model to /data/Text_Summarizer/models/checkpoints/ZH_BertEncoderTransformer_ckiplab-albert-tiny-chinese_2-6layers_1projlayers_tune0layers_8heads_256embed_512hidden_0.2dropout_gelu_9230tarvocab_0.0005initlr_45310warmup_AdamWeightDecay_64batchsize_8192shuffle_289936samples_100%Teacher/ckpt\n",
      "4531/4531 [==============================] - 1449s 320ms/step - loss: 3.4891 - accuracy: 0.4141 - val_loss: 3.2214 - val_accuracy: 0.4619\n",
      "Epoch 5/100\n",
      "4531/4531 [==============================] - ETA: 0s - loss: 3.2040 - accuracy: 0.4521\n",
      "    Input: 近 日 ， 有 網 友 反 映 ， 黑 龍 江 移 動 公 司 疑 似 私 自 為 客 戶 套 送 增 值 付 費 套 餐 ， 這 些 業 務 並 沒 有 經 過 客 戶 的 主 觀 同 意 。 舉 報 問 題 的 網 友 認 為 ， 其 個 人 資 訊 的 安 全 受 到 了 嚴 重 威 脅 。 對 此 ， 移 動 公 司 表 示 正 在 調 查 ， 並 將 於 14 日 給 出 回 覆 。\n",
      "    Target: 中 移 動 被 爆 私 自 增 減 客 戶 業 務 迴 應 稱 正 調 查\n",
      "    Predict: 黑 龍 江 移 動 公 司 私 自 套 送 套 餐 : 正 在 調 查\n",
      "\n",
      "    Input: 截 至 2013 年 9 月 30 日 的 六 個 月 裡 ， 銷 售 收 入 617 億 日 元 ( 6. 26 億 美 元 ) ， 同 比 增 長 1 % 。 然 而 淨 收 入 方 面 的 增 長 更 為 突 出 ， 去 年 同 期 該 公 司 還 處 於 虧 損 狀 態 ， 而 今 年 則 從 原 來 的 55 億 日 元 ( 5600 萬 美 元 ) 虧 損 轉 成 了 26 億 日 元 ( 2600 萬 美 元 ) 的 盈 利 。\n",
      "    Target: 扭 虧 為 盈 [UNK] 上 半 財 年 收 6 . [UNK] 億 美 元\n",
      "    Predict: 六 個 月 銷 售 收 入 同 比 增 長 1 %\n",
      "\n",
      "    Input: 最 近 ， 一 款 名 為 雷 達 - 密 碼 破 解 器 的 蹭 網 神 器 在 街 頭 攤 點 上 時 有 出 現 。 商 家 叫 賣 稱 1 其 可 以 獲 取 周 邊 電 腦 網 路 的 - 熱 點 資 訊 ， 並 自 動 破 解 密 碼 ， 終 身 不 用 付 網 費 。 它 其 實 是 一 個 用 供 電 的 的 發 光 二 極 體 。\n",
      "    Target: 榕 街 頭 現 - 密 碼 破 解 器 實 為 地 攤 騙 錢 神 器\n",
      "    Predict: 雷 達 - 密 碼 破 解 器 : 網 神 器 終 身 不 用 付 網 費\n",
      "\n",
      "Epoch 00005: val_loss improved from 3.22140 to 3.07629, saving model to /data/Text_Summarizer/models/checkpoints/ZH_BertEncoderTransformer_ckiplab-albert-tiny-chinese_2-6layers_1projlayers_tune0layers_8heads_256embed_512hidden_0.2dropout_gelu_9230tarvocab_0.0005initlr_45310warmup_AdamWeightDecay_64batchsize_8192shuffle_289936samples_100%Teacher/ckpt\n",
      "4531/4531 [==============================] - 1450s 320ms/step - loss: 3.2040 - accuracy: 0.4521 - val_loss: 3.0763 - val_accuracy: 0.4794\n",
      "Epoch 6/100\n",
      "4531/4531 [==============================] - ETA: 0s - loss: 3.0673 - accuracy: 0.4684\n",
      "    Input: 近 日 ， 有 網 友 反 映 ， 黑 龍 江 移 動 公 司 疑 似 私 自 為 客 戶 套 送 增 值 付 費 套 餐 ， 這 些 業 務 並 沒 有 經 過 客 戶 的 主 觀 同 意 。 舉 報 問 題 的 網 友 認 為 ， 其 個 人 資 訊 的 安 全 受 到 了 嚴 重 威 脅 。 對 此 ， 移 動 公 司 表 示 正 在 調 查 ， 並 將 於 14 日 給 出 回 覆 。\n",
      "    Target: 中 移 動 被 爆 私 自 增 減 客 戶 業 務 迴 應 稱 正 調 查\n",
      "    Predict: 黑 龍 江 移 動 公 司 私 自 套 送 增 值 套 餐\n",
      "\n",
      "    Input: 網 際 網 路 對 裝 修 使 用 者 的 影 響 ， 造 就 了 網 際 網 路 對 家 居 行 業 的 影 響 。 齊 家 網 做 了 很 多 工 作 。 主 要 分 成 兩 部 分 ： 一 部 分 圍 繞 網 際 網 路 思 維 ， 把 體 驗 、 極 致 、 創 新 做 透 。 第 二 部 分 圍 繞 著 家 居 ， 通 過 團 購 、 商 城 、 體 驗 館 形 成 了 齊 家 2 模 式 。\n",
      "    Target: 2 案 例 : 齊 家 如 何 應 對 2 帶 來 的 家 居 變 革\n",
      "    Predict: 齊 家 2 : 網 際 網 路 的 創 新 思 維\n",
      "\n",
      "    Input: 最 近 ， 一 款 名 為 雷 達 - 密 碼 破 解 器 的 蹭 網 神 器 在 街 頭 攤 點 上 時 有 出 現 。 商 家 叫 賣 稱 1 其 可 以 獲 取 周 邊 電 腦 網 路 的 - 熱 點 資 訊 ， 並 自 動 破 解 密 碼 ， 終 身 不 用 付 網 費 。 它 其 實 是 一 個 用 供 電 的 的 發 光 二 極 體 。\n",
      "    Target: 榕 街 頭 現 - 密 碼 破 解 器 實 為 地 攤 騙 錢 神 器\n",
      "    Predict: 雷 達 - 密 碼 破 解\n",
      "\n",
      "Epoch 00006: val_loss improved from 3.07629 to 2.97841, saving model to /data/Text_Summarizer/models/checkpoints/ZH_BertEncoderTransformer_ckiplab-albert-tiny-chinese_2-6layers_1projlayers_tune0layers_8heads_256embed_512hidden_0.2dropout_gelu_9230tarvocab_0.0005initlr_45310warmup_AdamWeightDecay_64batchsize_8192shuffle_289936samples_100%Teacher/ckpt\n",
      "4531/4531 [==============================] - 1449s 320ms/step - loss: 3.0673 - accuracy: 0.4684 - val_loss: 2.9784 - val_accuracy: 0.4913\n",
      "Epoch 7/100\n",
      "4531/4531 [==============================] - ETA: 0s - loss: 2.9884 - accuracy: 0.4772\n",
      "    Input: 網 際 網 路 對 裝 修 使 用 者 的 影 響 ， 造 就 了 網 際 網 路 對 家 居 行 業 的 影 響 。 齊 家 網 做 了 很 多 工 作 。 主 要 分 成 兩 部 分 ： 一 部 分 圍 繞 網 際 網 路 思 維 ， 把 體 驗 、 極 致 、 創 新 做 透 。 第 二 部 分 圍 繞 著 家 居 ， 通 過 團 購 、 商 城 、 體 驗 館 形 成 了 齊 家 2 模 式 。\n",
      "    Target: 2 案 例 : 齊 家 如 何 應 對 2 帶 來 的 家 居 變 革\n",
      "    Predict: 齊 家 2 模 式\n",
      "\n",
      "    Input: 在 上 海 自 貿 試 驗 區 的 示 範 效 應 下 ， 近 鄰 杭 州 試 圖 另 闢 蹊 徑 ， 主 攻 網 上 自 貿 試 驗 區 。 發 展 方 向 可 能 是 杭 州 正 全 力 試 點 的 跨 境 電 子 商 務 的 升 級 版 ， 提 法 已 引 起 國 家 相 關 部 委 高 度 重 視 ， 國 家 發 改 委 已 要 求 杭 州 儘 快 形 成 方 案 上 報 。\n",
      "    Target: 杭 州 網 上 自 貿 區 設 想 獲 認 可 發 改 委 要 求 上 報 方 案\n",
      "    Predict: 杭 州 試 點 網 上 自 貿 試 驗 區\n",
      "\n",
      "    Input: 近 日 ， 有 網 友 反 映 ， 黑 龍 江 移 動 公 司 疑 似 私 自 為 客 戶 套 送 增 值 付 費 套 餐 ， 這 些 業 務 並 沒 有 經 過 客 戶 的 主 觀 同 意 。 舉 報 問 題 的 網 友 認 為 ， 其 個 人 資 訊 的 安 全 受 到 了 嚴 重 威 脅 。 對 此 ， 移 動 公 司 表 示 正 在 調 查 ， 並 將 於 14 日 給 出 回 覆 。\n",
      "    Target: 中 移 動 被 爆 私 自 增 減 客 戶 業 務 迴 應 稱 正 調 查\n",
      "    Predict: 黑 龍 江 移 動 公 司 私 自 為 客 戶 套 送 增 值 套 餐\n",
      "\n",
      "Epoch 00007: val_loss improved from 2.97841 to 2.95481, saving model to /data/Text_Summarizer/models/checkpoints/ZH_BertEncoderTransformer_ckiplab-albert-tiny-chinese_2-6layers_1projlayers_tune0layers_8heads_256embed_512hidden_0.2dropout_gelu_9230tarvocab_0.0005initlr_45310warmup_AdamWeightDecay_64batchsize_8192shuffle_289936samples_100%Teacher/ckpt\n",
      "4531/4531 [==============================] - 1449s 320ms/step - loss: 2.9884 - accuracy: 0.4772 - val_loss: 2.9548 - val_accuracy: 0.4950\n",
      "Epoch 8/100\n",
      "4531/4531 [==============================] - ETA: 0s - loss: 2.9374 - accuracy: 0.4830\n",
      "    Input: 近 日 ， 有 網 友 反 映 ， 黑 龍 江 移 動 公 司 疑 似 私 自 為 客 戶 套 送 增 值 付 費 套 餐 ， 這 些 業 務 並 沒 有 經 過 客 戶 的 主 觀 同 意 。 舉 報 問 題 的 網 友 認 為 ， 其 個 人 資 訊 的 安 全 受 到 了 嚴 重 威 脅 。 對 此 ， 移 動 公 司 表 示 正 在 調 查 ， 並 將 於 14 日 給 出 回 覆 。\n",
      "    Target: 中 移 動 被 爆 私 自 增 減 客 戶 業 務 迴 應 稱 正 調 查\n",
      "    Predict: 黑 龍 江 移 動 公 司 私 自 為 客 戶 套 送 套 餐\n",
      "\n",
      "    Input: 網 際 網 路 對 裝 修 使 用 者 的 影 響 ， 造 就 了 網 際 網 路 對 家 居 行 業 的 影 響 。 齊 家 網 做 了 很 多 工 作 。 主 要 分 成 兩 部 分 ： 一 部 分 圍 繞 網 際 網 路 思 維 ， 把 體 驗 、 極 致 、 創 新 做 透 。 第 二 部 分 圍 繞 著 家 居 ， 通 過 團 購 、 商 城 、 體 驗 館 形 成 了 齊 家 2 模 式 。\n",
      "    Target: 2 案 例 : 齊 家 如 何 應 對 2 帶 來 的 家 居 變 革\n",
      "    Predict: 齊 家 網 的 網 際 網 路 思 維\n",
      "\n",
      "    Input: 最 近 ， 一 款 名 為 雷 達 - 密 碼 破 解 器 的 蹭 網 神 器 在 街 頭 攤 點 上 時 有 出 現 。 商 家 叫 賣 稱 1 其 可 以 獲 取 周 邊 電 腦 網 路 的 - 熱 點 資 訊 ， 並 自 動 破 解 密 碼 ， 終 身 不 用 付 網 費 。 它 其 實 是 一 個 用 供 電 的 的 發 光 二 極 體 。\n",
      "    Target: 榕 街 頭 現 - 密 碼 破 解 器 實 為 地 攤 騙 錢 神 器\n",
      "    Predict: [UNK] 網 神 器 破 解 器\n",
      "\n",
      "Epoch 00008: val_loss improved from 2.95481 to 2.92186, saving model to /data/Text_Summarizer/models/checkpoints/ZH_BertEncoderTransformer_ckiplab-albert-tiny-chinese_2-6layers_1projlayers_tune0layers_8heads_256embed_512hidden_0.2dropout_gelu_9230tarvocab_0.0005initlr_45310warmup_AdamWeightDecay_64batchsize_8192shuffle_289936samples_100%Teacher/ckpt\n",
      "4531/4531 [==============================] - 1450s 320ms/step - loss: 2.9374 - accuracy: 0.4830 - val_loss: 2.9219 - val_accuracy: 0.4980\n",
      "Epoch 9/100\n",
      "4531/4531 [==============================] - ETA: 0s - loss: 2.9013 - accuracy: 0.4871\n",
      "    Input: 近 日 ， 有 網 友 反 映 ， 黑 龍 江 移 動 公 司 疑 似 私 自 為 客 戶 套 送 增 值 付 費 套 餐 ， 這 些 業 務 並 沒 有 經 過 客 戶 的 主 觀 同 意 。 舉 報 問 題 的 網 友 認 為 ， 其 個 人 資 訊 的 安 全 受 到 了 嚴 重 威 脅 。 對 此 ， 移 動 公 司 表 示 正 在 調 查 ， 並 將 於 14 日 給 出 回 覆 。\n",
      "    Target: 中 移 動 被 爆 私 自 增 減 客 戶 業 務 迴 應 稱 正 調 查\n",
      "    Predict: 黑 龍 江 移 動 公 司 私 自 為 客 戶 套 送 套 餐\n",
      "\n",
      "    Input: 截 至 2013 年 9 月 30 日 的 六 個 月 裡 ， 銷 售 收 入 617 億 日 元 ( 6. 26 億 美 元 ) ， 同 比 增 長 1 % 。 然 而 淨 收 入 方 面 的 增 長 更 為 突 出 ， 去 年 同 期 該 公 司 還 處 於 虧 損 狀 態 ， 而 今 年 則 從 原 來 的 55 億 日 元 ( 5600 萬 美 元 ) 虧 損 轉 成 了 26 億 日 元 ( 2600 萬 美 元 ) 的 盈 利 。\n",
      "    Target: 扭 虧 為 盈 [UNK] 上 半 財 年 收 6 . [UNK] 億 美 元\n",
      "    Predict: [UNK] 年 銷 售 收 入 [UNK] 億 美 元 同 比 增 長 1 %\n",
      "\n",
      "    Input: 網 際 網 路 對 裝 修 使 用 者 的 影 響 ， 造 就 了 網 際 網 路 對 家 居 行 業 的 影 響 。 齊 家 網 做 了 很 多 工 作 。 主 要 分 成 兩 部 分 ： 一 部 分 圍 繞 網 際 網 路 思 維 ， 把 體 驗 、 極 致 、 創 新 做 透 。 第 二 部 分 圍 繞 著 家 居 ， 通 過 團 購 、 商 城 、 體 驗 館 形 成 了 齊 家 2 模 式 。\n",
      "    Target: 2 案 例 : 齊 家 如 何 應 對 2 帶 來 的 家 居 變 革\n",
      "    Predict: 齊 家 網 : 網 際 網 路 的 網 路 創 新 思 維\n",
      "\n",
      "Epoch 00009: val_loss improved from 2.92186 to 2.89265, saving model to /data/Text_Summarizer/models/checkpoints/ZH_BertEncoderTransformer_ckiplab-albert-tiny-chinese_2-6layers_1projlayers_tune0layers_8heads_256embed_512hidden_0.2dropout_gelu_9230tarvocab_0.0005initlr_45310warmup_AdamWeightDecay_64batchsize_8192shuffle_289936samples_100%Teacher/ckpt\n",
      "4531/4531 [==============================] - 1449s 320ms/step - loss: 2.9013 - accuracy: 0.4871 - val_loss: 2.8927 - val_accuracy: 0.5027\n",
      "Epoch 10/100\n",
      "4531/4531 [==============================] - ETA: 0s - loss: 2.8770 - accuracy: 0.4896\n",
      "    Input: 近 日 ， 有 網 友 反 映 ， 黑 龍 江 移 動 公 司 疑 似 私 自 為 客 戶 套 送 增 值 付 費 套 餐 ， 這 些 業 務 並 沒 有 經 過 客 戶 的 主 觀 同 意 。 舉 報 問 題 的 網 友 認 為 ， 其 個 人 資 訊 的 安 全 受 到 了 嚴 重 威 脅 。 對 此 ， 移 動 公 司 表 示 正 在 調 查 ， 並 將 於 14 日 給 出 回 覆 。\n",
      "    Target: 中 移 動 被 爆 私 自 增 減 客 戶 業 務 迴 應 稱 正 調 查\n",
      "    Predict: 黑 龍 江 移 動 公 司 私 自 為 客 戶 套 送 套 餐\n",
      "\n",
      "    Input: 截 至 2013 年 9 月 30 日 的 六 個 月 裡 ， 銷 售 收 入 617 億 日 元 ( 6. 26 億 美 元 ) ， 同 比 增 長 1 % 。 然 而 淨 收 入 方 面 的 增 長 更 為 突 出 ， 去 年 同 期 該 公 司 還 處 於 虧 損 狀 態 ， 而 今 年 則 從 原 來 的 55 億 日 元 ( 5600 萬 美 元 ) 虧 損 轉 成 了 26 億 日 元 ( 2600 萬 美 元 ) 的 盈 利 。\n",
      "    Target: 扭 虧 為 盈 [UNK] 上 半 財 年 收 6 . [UNK] 億 美 元\n",
      "    Predict: 六 月 銷 售 收 入 同 比 增 長 1 %\n",
      "\n",
      "    Input: 網 際 網 路 對 裝 修 使 用 者 的 影 響 ， 造 就 了 網 際 網 路 對 家 居 行 業 的 影 響 。 齊 家 網 做 了 很 多 工 作 。 主 要 分 成 兩 部 分 ： 一 部 分 圍 繞 網 際 網 路 思 維 ， 把 體 驗 、 極 致 、 創 新 做 透 。 第 二 部 分 圍 繞 著 家 居 ， 通 過 團 購 、 商 城 、 體 驗 館 形 成 了 齊 家 2 模 式 。\n",
      "    Target: 2 案 例 : 齊 家 如 何 應 對 2 帶 來 的 家 居 變 革\n",
      "    Predict: 齊 家 網 的 網 際 網 路 思 維 與 體 驗\n",
      "\n",
      "Epoch 00010: val_loss improved from 2.89265 to 2.87354, saving model to /data/Text_Summarizer/models/checkpoints/ZH_BertEncoderTransformer_ckiplab-albert-tiny-chinese_2-6layers_1projlayers_tune0layers_8heads_256embed_512hidden_0.2dropout_gelu_9230tarvocab_0.0005initlr_45310warmup_AdamWeightDecay_64batchsize_8192shuffle_289936samples_100%Teacher/ckpt\n",
      "4531/4531 [==============================] - 1449s 320ms/step - loss: 2.8770 - accuracy: 0.4896 - val_loss: 2.8735 - val_accuracy: 0.5023\n",
      "Epoch 11/100\n",
      "4531/4531 [==============================] - ETA: 0s - loss: 2.8056 - accuracy: 0.4981\n",
      "    Input: 近 日 ， 有 網 友 反 映 ， 黑 龍 江 移 動 公 司 疑 似 私 自 為 客 戶 套 送 增 值 付 費 套 餐 ， 這 些 業 務 並 沒 有 經 過 客 戶 的 主 觀 同 意 。 舉 報 問 題 的 網 友 認 為 ， 其 個 人 資 訊 的 安 全 受 到 了 嚴 重 威 脅 。 對 此 ， 移 動 公 司 表 示 正 在 調 查 ， 並 將 於 14 日 給 出 回 覆 。\n",
      "    Target: 中 移 動 被 爆 私 自 增 減 客 戶 業 務 迴 應 稱 正 調 查\n",
      "    Predict: 黑 龍 江 移 動 公 司 私 自 套 送 套 餐 網 友 : 正 回 覆\n",
      "\n",
      "    Input: 截 至 2013 年 9 月 30 日 的 六 個 月 裡 ， 銷 售 收 入 617 億 日 元 ( 6. 26 億 美 元 ) ， 同 比 增 長 1 % 。 然 而 淨 收 入 方 面 的 增 長 更 為 突 出 ， 去 年 同 期 該 公 司 還 處 於 虧 損 狀 態 ， 而 今 年 則 從 原 來 的 55 億 日 元 ( 5600 萬 美 元 ) 虧 損 轉 成 了 26 億 日 元 ( 2600 萬 美 元 ) 的 盈 利 。\n",
      "    Target: 扭 虧 為 盈 [UNK] 上 半 財 年 收 6 . [UNK] 億 美 元\n",
      "    Predict: 六 個 月 銷 售 收 入 同 比 增 長 1 %\n",
      "\n",
      "    Input: 網 際 網 路 對 裝 修 使 用 者 的 影 響 ， 造 就 了 網 際 網 路 對 家 居 行 業 的 影 響 。 齊 家 網 做 了 很 多 工 作 。 主 要 分 成 兩 部 分 ： 一 部 分 圍 繞 網 際 網 路 思 維 ， 把 體 驗 、 極 致 、 創 新 做 透 。 第 二 部 分 圍 繞 著 家 居 ， 通 過 團 購 、 商 城 、 體 驗 館 形 成 了 齊 家 2 模 式 。\n",
      "    Target: 2 案 例 : 齊 家 如 何 應 對 2 帶 來 的 家 居 變 革\n",
      "    Predict: 網 際 網 路 齊 家 2 模 式\n",
      "\n",
      "Epoch 00011: val_loss improved from 2.87354 to 2.81449, saving model to /data/Text_Summarizer/models/checkpoints/ZH_BertEncoderTransformer_ckiplab-albert-tiny-chinese_2-6layers_1projlayers_tune0layers_8heads_256embed_512hidden_0.2dropout_gelu_9230tarvocab_0.0005initlr_45310warmup_AdamWeightDecay_64batchsize_8192shuffle_289936samples_100%Teacher/ckpt\n",
      "4531/4531 [==============================] - 1449s 320ms/step - loss: 2.8056 - accuracy: 0.4981 - val_loss: 2.8145 - val_accuracy: 0.5102\n",
      "Epoch 12/100\n",
      "4531/4531 [==============================] - ETA: 0s - loss: 2.7481 - accuracy: 0.5047\n",
      "    Input: 近 日 ， 有 網 友 反 映 ， 黑 龍 江 移 動 公 司 疑 似 私 自 為 客 戶 套 送 增 值 付 費 套 餐 ， 這 些 業 務 並 沒 有 經 過 客 戶 的 主 觀 同 意 。 舉 報 問 題 的 網 友 認 為 ， 其 個 人 資 訊 的 安 全 受 到 了 嚴 重 威 脅 。 對 此 ， 移 動 公 司 表 示 正 在 調 查 ， 並 將 於 14 日 給 出 回 覆 。\n",
      "    Target: 中 移 動 被 爆 私 自 增 減 客 戶 業 務 迴 應 稱 正 調 查\n",
      "    Predict: 黑 龍 江 移 動 公 司 私 自 為 客 戶 套 送 套 餐\n",
      "\n",
      "    Input: 截 至 2013 年 9 月 30 日 的 六 個 月 裡 ， 銷 售 收 入 617 億 日 元 ( 6. 26 億 美 元 ) ， 同 比 增 長 1 % 。 然 而 淨 收 入 方 面 的 增 長 更 為 突 出 ， 去 年 同 期 該 公 司 還 處 於 虧 損 狀 態 ， 而 今 年 則 從 原 來 的 55 億 日 元 ( 5600 萬 美 元 ) 虧 損 轉 成 了 26 億 日 元 ( 2600 萬 美 元 ) 的 盈 利 。\n",
      "    Target: 扭 虧 為 盈 [UNK] 上 半 財 年 收 6 . [UNK] 億 美 元\n",
      "    Predict: 六 個 月 淨 收 入 同 比 增 長 1 %\n",
      "\n",
      "    Input: 網 際 網 路 對 裝 修 使 用 者 的 影 響 ， 造 就 了 網 際 網 路 對 家 居 行 業 的 影 響 。 齊 家 網 做 了 很 多 工 作 。 主 要 分 成 兩 部 分 ： 一 部 分 圍 繞 網 際 網 路 思 維 ， 把 體 驗 、 極 致 、 創 新 做 透 。 第 二 部 分 圍 繞 著 家 居 ， 通 過 團 購 、 商 城 、 體 驗 館 形 成 了 齊 家 2 模 式 。\n",
      "    Target: 2 案 例 : 齊 家 如 何 應 對 2 帶 來 的 家 居 變 革\n",
      "    Predict: 齊 家 網 的 網 際 網 路 思 維\n",
      "\n",
      "Epoch 00012: val_loss improved from 2.81449 to 2.78269, saving model to /data/Text_Summarizer/models/checkpoints/ZH_BertEncoderTransformer_ckiplab-albert-tiny-chinese_2-6layers_1projlayers_tune0layers_8heads_256embed_512hidden_0.2dropout_gelu_9230tarvocab_0.0005initlr_45310warmup_AdamWeightDecay_64batchsize_8192shuffle_289936samples_100%Teacher/ckpt\n",
      "4531/4531 [==============================] - 1449s 320ms/step - loss: 2.7481 - accuracy: 0.5047 - val_loss: 2.7827 - val_accuracy: 0.5154\n",
      "Epoch 13/100\n",
      "4531/4531 [==============================] - ETA: 0s - loss: 2.7014 - accuracy: 0.5102\n",
      "    Input: 近 日 ， 有 網 友 反 映 ， 黑 龍 江 移 動 公 司 疑 似 私 自 為 客 戶 套 送 增 值 付 費 套 餐 ， 這 些 業 務 並 沒 有 經 過 客 戶 的 主 觀 同 意 。 舉 報 問 題 的 網 友 認 為 ， 其 個 人 資 訊 的 安 全 受 到 了 嚴 重 威 脅 。 對 此 ， 移 動 公 司 表 示 正 在 調 查 ， 並 將 於 14 日 給 出 回 覆 。\n",
      "    Target: 中 移 動 被 爆 私 自 增 減 客 戶 業 務 迴 應 稱 正 調 查\n",
      "    Predict: 黑 龍 江 移 動 公 司 私 套 送 增 值 套 餐\n",
      "\n",
      "    Input: 截 至 2013 年 9 月 30 日 的 六 個 月 裡 ， 銷 售 收 入 617 億 日 元 ( 6. 26 億 美 元 ) ， 同 比 增 長 1 % 。 然 而 淨 收 入 方 面 的 增 長 更 為 突 出 ， 去 年 同 期 該 公 司 還 處 於 虧 損 狀 態 ， 而 今 年 則 從 原 來 的 55 億 日 元 ( 5600 萬 美 元 ) 虧 損 轉 成 了 26 億 日 元 ( 2600 萬 美 元 ) 的 盈 利 。\n",
      "    Target: 扭 虧 為 盈 [UNK] 上 半 財 年 收 6 . [UNK] 億 美 元\n",
      "    Predict: 六 個 月 淨 收 入 同 比 增 長 1 %\n",
      "\n",
      "    Input: 網 際 網 路 對 裝 修 使 用 者 的 影 響 ， 造 就 了 網 際 網 路 對 家 居 行 業 的 影 響 。 齊 家 網 做 了 很 多 工 作 。 主 要 分 成 兩 部 分 ： 一 部 分 圍 繞 網 際 網 路 思 維 ， 把 體 驗 、 極 致 、 創 新 做 透 。 第 二 部 分 圍 繞 著 家 居 ， 通 過 團 購 、 商 城 、 體 驗 館 形 成 了 齊 家 2 模 式 。\n",
      "    Target: 2 案 例 : 齊 家 如 何 應 對 2 帶 來 的 家 居 變 革\n",
      "    Predict: 齊 家 網 : 網 際 網 路 的 影 響\n",
      "\n",
      "Epoch 00013: val_loss improved from 2.78269 to 2.76437, saving model to /data/Text_Summarizer/models/checkpoints/ZH_BertEncoderTransformer_ckiplab-albert-tiny-chinese_2-6layers_1projlayers_tune0layers_8heads_256embed_512hidden_0.2dropout_gelu_9230tarvocab_0.0005initlr_45310warmup_AdamWeightDecay_64batchsize_8192shuffle_289936samples_100%Teacher/ckpt\n",
      "4531/4531 [==============================] - 1449s 320ms/step - loss: 2.7014 - accuracy: 0.5102 - val_loss: 2.7644 - val_accuracy: 0.5171\n",
      "Epoch 14/100\n",
      "4531/4531 [==============================] - ETA: 0s - loss: 2.6615 - accuracy: 0.5152\n",
      "    Input: 近 日 ， 有 網 友 反 映 ， 黑 龍 江 移 動 公 司 疑 似 私 自 為 客 戶 套 送 增 值 付 費 套 餐 ， 這 些 業 務 並 沒 有 經 過 客 戶 的 主 觀 同 意 。 舉 報 問 題 的 網 友 認 為 ， 其 個 人 資 訊 的 安 全 受 到 了 嚴 重 威 脅 。 對 此 ， 移 動 公 司 表 示 正 在 調 查 ， 並 將 於 14 日 給 出 回 覆 。\n",
      "    Target: 中 移 動 被 爆 私 自 增 減 客 戶 業 務 迴 應 稱 正 調 查\n",
      "    Predict: 黑 龍 江 移 動 公 司 私 自 為 客 戶 套 送 增 值 套 餐\n",
      "\n",
      "    Input: 截 至 2013 年 9 月 30 日 的 六 個 月 裡 ， 銷 售 收 入 617 億 日 元 ( 6. 26 億 美 元 ) ， 同 比 增 長 1 % 。 然 而 淨 收 入 方 面 的 增 長 更 為 突 出 ， 去 年 同 期 該 公 司 還 處 於 虧 損 狀 態 ， 而 今 年 則 從 原 來 的 55 億 日 元 ( 5600 萬 美 元 ) 虧 損 轉 成 了 26 億 日 元 ( 2600 萬 美 元 ) 的 盈 利 。\n",
      "    Target: 扭 虧 為 盈 [UNK] 上 半 財 年 收 6 . [UNK] 億 美 元\n",
      "    Predict: 六 個 月 銷 售 收 入 同 比 增 長 1 %\n",
      "\n",
      "    Input: 網 際 網 路 對 裝 修 使 用 者 的 影 響 ， 造 就 了 網 際 網 路 對 家 居 行 業 的 影 響 。 齊 家 網 做 了 很 多 工 作 。 主 要 分 成 兩 部 分 ： 一 部 分 圍 繞 網 際 網 路 思 維 ， 把 體 驗 、 極 致 、 創 新 做 透 。 第 二 部 分 圍 繞 著 家 居 ， 通 過 團 購 、 商 城 、 體 驗 館 形 成 了 齊 家 2 模 式 。\n",
      "    Target: 2 案 例 : 齊 家 如 何 應 對 2 帶 來 的 家 居 變 革\n",
      "    Predict: 齊 家 網 : 網 際 網 路 與 家 居\n",
      "\n",
      "Epoch 00014: val_loss improved from 2.76437 to 2.73041, saving model to /data/Text_Summarizer/models/checkpoints/ZH_BertEncoderTransformer_ckiplab-albert-tiny-chinese_2-6layers_1projlayers_tune0layers_8heads_256embed_512hidden_0.2dropout_gelu_9230tarvocab_0.0005initlr_45310warmup_AdamWeightDecay_64batchsize_8192shuffle_289936samples_100%Teacher/ckpt\n",
      "4531/4531 [==============================] - 1449s 320ms/step - loss: 2.6615 - accuracy: 0.5152 - val_loss: 2.7304 - val_accuracy: 0.5220\n",
      "Epoch 15/100\n",
      "4531/4531 [==============================] - ETA: 0s - loss: 2.6245 - accuracy: 0.5196\n",
      "    Input: 近 日 ， 有 網 友 反 映 ， 黑 龍 江 移 動 公 司 疑 似 私 自 為 客 戶 套 送 增 值 付 費 套 餐 ， 這 些 業 務 並 沒 有 經 過 客 戶 的 主 觀 同 意 。 舉 報 問 題 的 網 友 認 為 ， 其 個 人 資 訊 的 安 全 受 到 了 嚴 重 威 脅 。 對 此 ， 移 動 公 司 表 示 正 在 調 查 ， 並 將 於 14 日 給 出 回 覆 。\n",
      "    Target: 中 移 動 被 爆 私 自 增 減 客 戶 業 務 迴 應 稱 正 調 查\n",
      "    Predict: 黑 龍 江 移 動 公 司 私 自 為 客 戶 套 送 增 值 付 費 套 餐\n",
      "\n",
      "    Input: 截 至 2013 年 9 月 30 日 的 六 個 月 裡 ， 銷 售 收 入 617 億 日 元 ( 6. 26 億 美 元 ) ， 同 比 增 長 1 % 。 然 而 淨 收 入 方 面 的 增 長 更 為 突 出 ， 去 年 同 期 該 公 司 還 處 於 虧 損 狀 態 ， 而 今 年 則 從 原 來 的 55 億 日 元 ( 5600 萬 美 元 ) 虧 損 轉 成 了 26 億 日 元 ( 2600 萬 美 元 ) 的 盈 利 。\n",
      "    Target: 扭 虧 為 盈 [UNK] 上 半 財 年 收 6 . [UNK] 億 美 元\n",
      "    Predict: 六 月 淨 收 入 同 比 增 長 1 %\n",
      "\n",
      "    Input: 網 際 網 路 對 裝 修 使 用 者 的 影 響 ， 造 就 了 網 際 網 路 對 家 居 行 業 的 影 響 。 齊 家 網 做 了 很 多 工 作 。 主 要 分 成 兩 部 分 ： 一 部 分 圍 繞 網 際 網 路 思 維 ， 把 體 驗 、 極 致 、 創 新 做 透 。 第 二 部 分 圍 繞 著 家 居 ， 通 過 團 購 、 商 城 、 體 驗 館 形 成 了 齊 家 2 模 式 。\n",
      "    Target: 2 案 例 : 齊 家 如 何 應 對 2 帶 來 的 家 居 變 革\n",
      "    Predict: 齊 家 網 的 網 際 網 路 思 維\n",
      "\n",
      "Epoch 00015: val_loss improved from 2.73041 to 2.72392, saving model to /data/Text_Summarizer/models/checkpoints/ZH_BertEncoderTransformer_ckiplab-albert-tiny-chinese_2-6layers_1projlayers_tune0layers_8heads_256embed_512hidden_0.2dropout_gelu_9230tarvocab_0.0005initlr_45310warmup_AdamWeightDecay_64batchsize_8192shuffle_289936samples_100%Teacher/ckpt\n",
      "4531/4531 [==============================] - 1449s 320ms/step - loss: 2.6245 - accuracy: 0.5196 - val_loss: 2.7239 - val_accuracy: 0.5230\n",
      "Epoch 16/100\n",
      "4531/4531 [==============================] - ETA: 0s - loss: 2.5930 - accuracy: 0.5236\n",
      "    Input: 網 際 網 路 對 裝 修 使 用 者 的 影 響 ， 造 就 了 網 際 網 路 對 家 居 行 業 的 影 響 。 齊 家 網 做 了 很 多 工 作 。 主 要 分 成 兩 部 分 ： 一 部 分 圍 繞 網 際 網 路 思 維 ， 把 體 驗 、 極 致 、 創 新 做 透 。 第 二 部 分 圍 繞 著 家 居 ， 通 過 團 購 、 商 城 、 體 驗 館 形 成 了 齊 家 2 模 式 。\n",
      "    Target: 2 案 例 : 齊 家 如 何 應 對 2 帶 來 的 家 居 變 革\n",
      "    Predict: 齊 家 網 第 二 部 分 圍 繞 網 際 網 路 思 維\n",
      "\n",
      "    Input: 近 日 ， 有 網 友 反 映 ， 黑 龍 江 移 動 公 司 疑 似 私 自 為 客 戶 套 送 增 值 付 費 套 餐 ， 這 些 業 務 並 沒 有 經 過 客 戶 的 主 觀 同 意 。 舉 報 問 題 的 網 友 認 為 ， 其 個 人 資 訊 的 安 全 受 到 了 嚴 重 威 脅 。 對 此 ， 移 動 公 司 表 示 正 在 調 查 ， 並 將 於 14 日 給 出 回 覆 。\n",
      "    Target: 中 移 動 被 爆 私 自 增 減 客 戶 業 務 迴 應 稱 正 調 查\n",
      "    Predict: 黑 龍 江 移 動 私 自 為 客 戶 套 送 增 值 費\n",
      "\n",
      "    Input: 本 以 為 買 的 是 銀 行 理 財 產 品 ， 沒 料 到 卻 是 客 戶 經 理 違 規 代 銷 的 貴 金 屬 產 品 ， 農 行 北 京 分 行 客 戶 張 呈 360 萬 資 金 不 翼 而 飛 。 此 後 ， 理 財 經 理 閃 電 辭 職 ， 農 行 稱 非 銀 行 產 品 拒 絕 承 擔 責 任 。\n",
      "    Target: 農 行 客 戶 [UNK] 萬 遭 遇 飛 單 銀 行 稱 非 銀 行 產 品 不 擔 責 任\n",
      "    Predict: 農 行 理 財 經 理 閃 電 辭 職\n",
      "\n",
      "Epoch 00016: val_loss improved from 2.72392 to 2.70219, saving model to /data/Text_Summarizer/models/checkpoints/ZH_BertEncoderTransformer_ckiplab-albert-tiny-chinese_2-6layers_1projlayers_tune0layers_8heads_256embed_512hidden_0.2dropout_gelu_9230tarvocab_0.0005initlr_45310warmup_AdamWeightDecay_64batchsize_8192shuffle_289936samples_100%Teacher/ckpt\n",
      "4531/4531 [==============================] - 1450s 320ms/step - loss: 2.5930 - accuracy: 0.5236 - val_loss: 2.7022 - val_accuracy: 0.5253\n",
      "Epoch 17/100\n",
      "4531/4531 [==============================] - ETA: 0s - loss: 2.5639 - accuracy: 0.5269\n",
      "    Input: 近 日 ， 有 網 友 反 映 ， 黑 龍 江 移 動 公 司 疑 似 私 自 為 客 戶 套 送 增 值 付 費 套 餐 ， 這 些 業 務 並 沒 有 經 過 客 戶 的 主 觀 同 意 。 舉 報 問 題 的 網 友 認 為 ， 其 個 人 資 訊 的 安 全 受 到 了 嚴 重 威 脅 。 對 此 ， 移 動 公 司 表 示 正 在 調 查 ， 並 將 於 14 日 給 出 回 覆 。\n",
      "    Target: 中 移 動 被 爆 私 自 增 減 客 戶 業 務 迴 應 稱 正 調 查\n",
      "    Predict: 黑 龍 江 移 動 私 自 為 客 戶 套 送 增 值 付 費 套 餐\n",
      "\n",
      "    Input: 截 至 2013 年 9 月 30 日 的 六 個 月 裡 ， 銷 售 收 入 617 億 日 元 ( 6. 26 億 美 元 ) ， 同 比 增 長 1 % 。 然 而 淨 收 入 方 面 的 增 長 更 為 突 出 ， 去 年 同 期 該 公 司 還 處 於 虧 損 狀 態 ， 而 今 年 則 從 原 來 的 55 億 日 元 ( 5600 萬 美 元 ) 虧 損 轉 成 了 26 億 日 元 ( 2600 萬 美 元 ) 的 盈 利 。\n",
      "    Target: 扭 虧 為 盈 [UNK] 上 半 財 年 收 6 . [UNK] 億 美 元\n",
      "    Predict: 六 個 月 淨 收 入 同 比 增 長 1 %\n",
      "\n",
      "    Input: 網 際 網 路 對 裝 修 使 用 者 的 影 響 ， 造 就 了 網 際 網 路 對 家 居 行 業 的 影 響 。 齊 家 網 做 了 很 多 工 作 。 主 要 分 成 兩 部 分 ： 一 部 分 圍 繞 網 際 網 路 思 維 ， 把 體 驗 、 極 致 、 創 新 做 透 。 第 二 部 分 圍 繞 著 家 居 ， 通 過 團 購 、 商 城 、 體 驗 館 形 成 了 齊 家 2 模 式 。\n",
      "    Target: 2 案 例 : 齊 家 如 何 應 對 2 帶 來 的 家 居 變 革\n",
      "    Predict: 齊 家 網 : 網 際 網 路 的 影 響\n",
      "\n",
      "Epoch 00017: val_loss improved from 2.70219 to 2.69994, saving model to /data/Text_Summarizer/models/checkpoints/ZH_BertEncoderTransformer_ckiplab-albert-tiny-chinese_2-6layers_1projlayers_tune0layers_8heads_256embed_512hidden_0.2dropout_gelu_9230tarvocab_0.0005initlr_45310warmup_AdamWeightDecay_64batchsize_8192shuffle_289936samples_100%Teacher/ckpt\n",
      "4531/4531 [==============================] - 1449s 320ms/step - loss: 2.5639 - accuracy: 0.5269 - val_loss: 2.6999 - val_accuracy: 0.5279\n",
      "Epoch 18/100\n",
      "4531/4531 [==============================] - ETA: 0s - loss: 2.5378 - accuracy: 0.5299\n",
      "    Input: 近 日 ， 有 網 友 反 映 ， 黑 龍 江 移 動 公 司 疑 似 私 自 為 客 戶 套 送 增 值 付 費 套 餐 ， 這 些 業 務 並 沒 有 經 過 客 戶 的 主 觀 同 意 。 舉 報 問 題 的 網 友 認 為 ， 其 個 人 資 訊 的 安 全 受 到 了 嚴 重 威 脅 。 對 此 ， 移 動 公 司 表 示 正 在 調 查 ， 並 將 於 14 日 給 出 回 覆 。\n",
      "    Target: 中 移 動 被 爆 私 自 增 減 客 戶 業 務 迴 應 稱 正 調 查\n",
      "    Predict: 黑 龍 江 移 動 公 司 私 自 套 餐 遭 質 疑\n",
      "\n",
      "    Input: 截 至 2013 年 9 月 30 日 的 六 個 月 裡 ， 銷 售 收 入 617 億 日 元 ( 6. 26 億 美 元 ) ， 同 比 增 長 1 % 。 然 而 淨 收 入 方 面 的 增 長 更 為 突 出 ， 去 年 同 期 該 公 司 還 處 於 虧 損 狀 態 ， 而 今 年 則 從 原 來 的 55 億 日 元 ( 5600 萬 美 元 ) 虧 損 轉 成 了 26 億 日 元 ( 2600 萬 美 元 ) 的 盈 利 。\n",
      "    Target: 扭 虧 為 盈 [UNK] 上 半 財 年 收 6 . [UNK] 億 美 元\n",
      "    Predict: 去 年 營 收 [UNK] 億 美 元 同 比 增 長 1 %\n",
      "\n",
      "    Input: 網 際 網 路 對 裝 修 使 用 者 的 影 響 ， 造 就 了 網 際 網 路 對 家 居 行 業 的 影 響 。 齊 家 網 做 了 很 多 工 作 。 主 要 分 成 兩 部 分 ： 一 部 分 圍 繞 網 際 網 路 思 維 ， 把 體 驗 、 極 致 、 創 新 做 透 。 第 二 部 分 圍 繞 著 家 居 ， 通 過 團 購 、 商 城 、 體 驗 館 形 成 了 齊 家 2 模 式 。\n",
      "    Target: 2 案 例 : 齊 家 如 何 應 對 2 帶 來 的 家 居 變 革\n",
      "    Predict: 齊 家 網 : 網 際 網 路 的 影 響\n",
      "\n",
      "Epoch 00018: val_loss improved from 2.69994 to 2.67975, saving model to /data/Text_Summarizer/models/checkpoints/ZH_BertEncoderTransformer_ckiplab-albert-tiny-chinese_2-6layers_1projlayers_tune0layers_8heads_256embed_512hidden_0.2dropout_gelu_9230tarvocab_0.0005initlr_45310warmup_AdamWeightDecay_64batchsize_8192shuffle_289936samples_100%Teacher/ckpt\n",
      "4531/4531 [==============================] - 1449s 320ms/step - loss: 2.5378 - accuracy: 0.5299 - val_loss: 2.6797 - val_accuracy: 0.5284\n",
      "Epoch 19/100\n",
      "4531/4531 [==============================] - ETA: 0s - loss: 2.5146 - accuracy: 0.5328\n",
      "    Input: 近 日 ， 有 網 友 反 映 ， 黑 龍 江 移 動 公 司 疑 似 私 自 為 客 戶 套 送 增 值 付 費 套 餐 ， 這 些 業 務 並 沒 有 經 過 客 戶 的 主 觀 同 意 。 舉 報 問 題 的 網 友 認 為 ， 其 個 人 資 訊 的 安 全 受 到 了 嚴 重 威 脅 。 對 此 ， 移 動 公 司 表 示 正 在 調 查 ， 並 將 於 14 日 給 出 回 覆 。\n",
      "    Target: 中 移 動 被 爆 私 自 增 減 客 戶 業 務 迴 應 稱 正 調 查\n",
      "    Predict: 黑 龍 江 移 動 公 司 私 自 套 送 增 值 付 費 套 餐\n",
      "\n",
      "    Input: 網 際 網 路 對 裝 修 使 用 者 的 影 響 ， 造 就 了 網 際 網 路 對 家 居 行 業 的 影 響 。 齊 家 網 做 了 很 多 工 作 。 主 要 分 成 兩 部 分 ： 一 部 分 圍 繞 網 際 網 路 思 維 ， 把 體 驗 、 極 致 、 創 新 做 透 。 第 二 部 分 圍 繞 著 家 居 ， 通 過 團 購 、 商 城 、 體 驗 館 形 成 了 齊 家 2 模 式 。\n",
      "    Target: 2 案 例 : 齊 家 如 何 應 對 2 帶 來 的 家 居 變 革\n",
      "    Predict: 齊 家 網 : 網 際 網 路 對 裝 修 使 用 者 影 響\n",
      "\n",
      "    Input: 最 近 ， 一 款 名 為 雷 達 - 密 碼 破 解 器 的 蹭 網 神 器 在 街 頭 攤 點 上 時 有 出 現 。 商 家 叫 賣 稱 1 其 可 以 獲 取 周 邊 電 腦 網 路 的 - 熱 點 資 訊 ， 並 自 動 破 解 密 碼 ， 終 身 不 用 付 網 費 。 它 其 實 是 一 個 用 供 電 的 的 發 光 二 極 體 。\n",
      "    Target: 榕 街 頭 現 - 密 碼 破 解 器 實 為 地 攤 騙 錢 神 器\n",
      "    Predict: 雷 達 - 密 碼 破 解 器 , 終 身 不 用 付 網 費\n",
      "\n",
      "Epoch 00019: val_loss improved from 2.67975 to 2.66161, saving model to /data/Text_Summarizer/models/checkpoints/ZH_BertEncoderTransformer_ckiplab-albert-tiny-chinese_2-6layers_1projlayers_tune0layers_8heads_256embed_512hidden_0.2dropout_gelu_9230tarvocab_0.0005initlr_45310warmup_AdamWeightDecay_64batchsize_8192shuffle_289936samples_100%Teacher/ckpt\n",
      "4531/4531 [==============================] - 1450s 320ms/step - loss: 2.5146 - accuracy: 0.5328 - val_loss: 2.6616 - val_accuracy: 0.5306\n",
      "Epoch 20/100\n",
      "4531/4531 [==============================] - ETA: 0s - loss: 2.4936 - accuracy: 0.5353\n",
      "    Input: 近 日 ， 有 網 友 反 映 ， 黑 龍 江 移 動 公 司 疑 似 私 自 為 客 戶 套 送 增 值 付 費 套 餐 ， 這 些 業 務 並 沒 有 經 過 客 戶 的 主 觀 同 意 。 舉 報 問 題 的 網 友 認 為 ， 其 個 人 資 訊 的 安 全 受 到 了 嚴 重 威 脅 。 對 此 ， 移 動 公 司 表 示 正 在 調 查 ， 並 將 於 14 日 給 出 回 覆 。\n",
      "    Target: 中 移 動 被 爆 私 自 增 減 客 戶 業 務 迴 應 稱 正 調 查\n",
      "    Predict: 黑 龍 江 移 動 公 司 私 自 為 客 戶 套 送 增 值 套 餐\n",
      "\n",
      "    Input: 最 近 ， 一 款 名 為 雷 達 - 密 碼 破 解 器 的 蹭 網 神 器 在 街 頭 攤 點 上 時 有 出 現 。 商 家 叫 賣 稱 1 其 可 以 獲 取 周 邊 電 腦 網 路 的 - 熱 點 資 訊 ， 並 自 動 破 解 密 碼 ， 終 身 不 用 付 網 費 。 它 其 實 是 一 個 用 供 電 的 的 發 光 二 極 體 。\n",
      "    Target: 榕 街 頭 現 - 密 碼 破 解 器 實 為 地 攤 騙 錢 神 器\n",
      "    Predict: 雷 達 - 密 碼 破 解 器 , 終 身 不 用 付 費 !\n",
      "\n",
      "    Input: 本 以 為 買 的 是 銀 行 理 財 產 品 ， 沒 料 到 卻 是 客 戶 經 理 違 規 代 銷 的 貴 金 屬 產 品 ， 農 行 北 京 分 行 客 戶 張 呈 360 萬 資 金 不 翼 而 飛 。 此 後 ， 理 財 經 理 閃 電 辭 職 ， 農 行 稱 非 銀 行 產 品 拒 絕 承 擔 責 任 。\n",
      "    Target: 農 行 客 戶 [UNK] 萬 遭 遇 飛 單 銀 行 稱 非 銀 行 產 品 不 擔 責 任\n",
      "    Predict: 農 行 北 京 分 行 客 戶 [UNK] 萬 資 金 不 翼 而 飛 理 財 經 理 閃 電 辭 職\n",
      "\n",
      "Epoch 00020: val_loss improved from 2.66161 to 2.65602, saving model to /data/Text_Summarizer/models/checkpoints/ZH_BertEncoderTransformer_ckiplab-albert-tiny-chinese_2-6layers_1projlayers_tune0layers_8heads_256embed_512hidden_0.2dropout_gelu_9230tarvocab_0.0005initlr_45310warmup_AdamWeightDecay_64batchsize_8192shuffle_289936samples_100%Teacher/ckpt\n",
      "4531/4531 [==============================] - 1446s 319ms/step - loss: 2.4936 - accuracy: 0.5353 - val_loss: 2.6560 - val_accuracy: 0.5304\n",
      "Epoch 21/100\n",
      "4531/4531 [==============================] - ETA: 0s - loss: 2.4713 - accuracy: 0.5381\n",
      "    Input: 截 至 2013 年 9 月 30 日 的 六 個 月 裡 ， 銷 售 收 入 617 億 日 元 ( 6. 26 億 美 元 ) ， 同 比 增 長 1 % 。 然 而 淨 收 入 方 面 的 增 長 更 為 突 出 ， 去 年 同 期 該 公 司 還 處 於 虧 損 狀 態 ， 而 今 年 則 從 原 來 的 55 億 日 元 ( 5600 萬 美 元 ) 虧 損 轉 成 了 26 億 日 元 ( 2600 萬 美 元 ) 的 盈 利 。\n",
      "    Target: 扭 虧 為 盈 [UNK] 上 半 財 年 收 6 . [UNK] 億 美 元\n",
      "    Predict: 去 年 銷 售 收 入 [UNK] 億 美 元 同 比 增 長 1 %\n",
      "\n",
      "    Input: 網 際 網 路 對 裝 修 使 用 者 的 影 響 ， 造 就 了 網 際 網 路 對 家 居 行 業 的 影 響 。 齊 家 網 做 了 很 多 工 作 。 主 要 分 成 兩 部 分 ： 一 部 分 圍 繞 網 際 網 路 思 維 ， 把 體 驗 、 極 致 、 創 新 做 透 。 第 二 部 分 圍 繞 著 家 居 ， 通 過 團 購 、 商 城 、 體 驗 館 形 成 了 齊 家 2 模 式 。\n",
      "    Target: 2 案 例 : 齊 家 如 何 應 對 2 帶 來 的 家 居 變 革\n",
      "    Predict: 齊 家 網 : 網 際 網 路 的 影 響\n",
      "\n",
      "    Input: 本 以 為 買 的 是 銀 行 理 財 產 品 ， 沒 料 到 卻 是 客 戶 經 理 違 規 代 銷 的 貴 金 屬 產 品 ， 農 行 北 京 分 行 客 戶 張 呈 360 萬 資 金 不 翼 而 飛 。 此 後 ， 理 財 經 理 閃 電 辭 職 ， 農 行 稱 非 銀 行 產 品 拒 絕 承 擔 責 任 。\n",
      "    Target: 農 行 客 戶 [UNK] 萬 遭 遇 飛 單 銀 行 稱 非 銀 行 產 品 不 擔 責 任\n",
      "    Predict: 農 行 北 京 分 行 客 戶 張 [UNK] 萬 資 金 不 翼 而 飛 理 財 經 理 閃 電 辭 職\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 2.65602\n",
      "4531/4531 [==============================] - 1444s 319ms/step - loss: 2.4713 - accuracy: 0.5381 - val_loss: 2.6611 - val_accuracy: 0.5327\n",
      "Epoch 22/100\n",
      "4531/4531 [==============================] - ETA: 0s - loss: 2.4522 - accuracy: 0.5406\n",
      "    Input: 近 日 ， 有 網 友 反 映 ， 黑 龍 江 移 動 公 司 疑 似 私 自 為 客 戶 套 送 增 值 付 費 套 餐 ， 這 些 業 務 並 沒 有 經 過 客 戶 的 主 觀 同 意 。 舉 報 問 題 的 網 友 認 為 ， 其 個 人 資 訊 的 安 全 受 到 了 嚴 重 威 脅 。 對 此 ， 移 動 公 司 表 示 正 在 調 查 ， 並 將 於 14 日 給 出 回 覆 。\n",
      "    Target: 中 移 動 被 爆 私 自 增 減 客 戶 業 務 迴 應 稱 正 調 查\n",
      "    Predict: 黑 龍 江 移 動 公 司 疑 為 客 戶 套 送 增 值 付 費 套 餐\n",
      "\n",
      "    Input: 網 際 網 路 對 裝 修 使 用 者 的 影 響 ， 造 就 了 網 際 網 路 對 家 居 行 業 的 影 響 。 齊 家 網 做 了 很 多 工 作 。 主 要 分 成 兩 部 分 ： 一 部 分 圍 繞 網 際 網 路 思 維 ， 把 體 驗 、 極 致 、 創 新 做 透 。 第 二 部 分 圍 繞 著 家 居 ， 通 過 團 購 、 商 城 、 體 驗 館 形 成 了 齊 家 2 模 式 。\n",
      "    Target: 2 案 例 : 齊 家 如 何 應 對 2 帶 來 的 家 居 變 革\n",
      "    Predict: 齊 家 網 : 網 際 網 路 對 裝 修 使 用 者 影 響 的 影 響\n",
      "\n",
      "    Input: 最 近 ， 一 款 名 為 雷 達 - 密 碼 破 解 器 的 蹭 網 神 器 在 街 頭 攤 點 上 時 有 出 現 。 商 家 叫 賣 稱 1 其 可 以 獲 取 周 邊 電 腦 網 路 的 - 熱 點 資 訊 ， 並 自 動 破 解 密 碼 ， 終 身 不 用 付 網 費 。 它 其 實 是 一 個 用 供 電 的 的 發 光 二 極 體 。\n",
      "    Target: 榕 街 頭 現 - 密 碼 破 解 器 實 為 地 攤 騙 錢 神 器\n",
      "    Predict: 雷 達 - 密 碼 破 解 器 密 碼\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 2.65602\n",
      "4531/4531 [==============================] - 1444s 319ms/step - loss: 2.4522 - accuracy: 0.5406 - val_loss: 2.6639 - val_accuracy: 0.5333\n",
      "Epoch 23/100\n",
      "4531/4531 [==============================] - ETA: 0s - loss: 2.4314 - accuracy: 0.5430\n",
      "    Input: 近 日 ， 有 網 友 反 映 ， 黑 龍 江 移 動 公 司 疑 似 私 自 為 客 戶 套 送 增 值 付 費 套 餐 ， 這 些 業 務 並 沒 有 經 過 客 戶 的 主 觀 同 意 。 舉 報 問 題 的 網 友 認 為 ， 其 個 人 資 訊 的 安 全 受 到 了 嚴 重 威 脅 。 對 此 ， 移 動 公 司 表 示 正 在 調 查 ， 並 將 於 14 日 給 出 回 覆 。\n",
      "    Target: 中 移 動 被 爆 私 自 增 減 客 戶 業 務 迴 應 稱 正 調 查\n",
      "    Predict: 黑 龍 江 移 動 公 司 私 自 為 客 戶 套 送 增 值 付 費 套 餐\n",
      "\n",
      "    Input: 截 至 2013 年 9 月 30 日 的 六 個 月 裡 ， 銷 售 收 入 617 億 日 元 ( 6. 26 億 美 元 ) ， 同 比 增 長 1 % 。 然 而 淨 收 入 方 面 的 增 長 更 為 突 出 ， 去 年 同 期 該 公 司 還 處 於 虧 損 狀 態 ， 而 今 年 則 從 原 來 的 55 億 日 元 ( 5600 萬 美 元 ) 虧 損 轉 成 了 26 億 日 元 ( 2600 萬 美 元 ) 的 盈 利 。\n",
      "    Target: 扭 虧 為 盈 [UNK] 上 半 財 年 收 6 . [UNK] 億 美 元\n",
      "    Predict: 日 本 去 年 淨 收 入 增 長 增 [UNK] %\n",
      "\n",
      "    Input: 最 近 ， 一 款 名 為 雷 達 - 密 碼 破 解 器 的 蹭 網 神 器 在 街 頭 攤 點 上 時 有 出 現 。 商 家 叫 賣 稱 1 其 可 以 獲 取 周 邊 電 腦 網 路 的 - 熱 點 資 訊 ， 並 自 動 破 解 密 碼 ， 終 身 不 用 付 網 費 。 它 其 實 是 一 個 用 供 電 的 的 發 光 二 極 體 。\n",
      "    Target: 榕 街 頭 現 - 密 碼 破 解 器 實 為 地 攤 騙 錢 神 器\n",
      "    Predict: 雷 達 - 密 碼 破 解 器\n",
      "\n",
      "Epoch 00023: val_loss improved from 2.65602 to 2.64967, saving model to /data/Text_Summarizer/models/checkpoints/ZH_BertEncoderTransformer_ckiplab-albert-tiny-chinese_2-6layers_1projlayers_tune0layers_8heads_256embed_512hidden_0.2dropout_gelu_9230tarvocab_0.0005initlr_45310warmup_AdamWeightDecay_64batchsize_8192shuffle_289936samples_100%Teacher/ckpt\n",
      "4531/4531 [==============================] - 1446s 319ms/step - loss: 2.4314 - accuracy: 0.5430 - val_loss: 2.6497 - val_accuracy: 0.5339\n",
      "Epoch 24/100\n",
      "4531/4531 [==============================] - ETA: 0s - loss: 2.4145 - accuracy: 0.5453\n",
      "    Input: 近 日 ， 有 網 友 反 映 ， 黑 龍 江 移 動 公 司 疑 似 私 自 為 客 戶 套 送 增 值 付 費 套 餐 ， 這 些 業 務 並 沒 有 經 過 客 戶 的 主 觀 同 意 。 舉 報 問 題 的 網 友 認 為 ， 其 個 人 資 訊 的 安 全 受 到 了 嚴 重 威 脅 。 對 此 ， 移 動 公 司 表 示 正 在 調 查 ， 並 將 於 14 日 給 出 回 覆 。\n",
      "    Target: 中 移 動 被 爆 私 自 增 減 客 戶 業 務 迴 應 稱 正 調 查\n",
      "    Predict: 黑 龍 江 移 動 公 司 私 自 為 客 戶 套 送 增 值 付 費 套 餐\n",
      "\n",
      "    Input: 截 至 2013 年 9 月 30 日 的 六 個 月 裡 ， 銷 售 收 入 617 億 日 元 ( 6. 26 億 美 元 ) ， 同 比 增 長 1 % 。 然 而 淨 收 入 方 面 的 增 長 更 為 突 出 ， 去 年 同 期 該 公 司 還 處 於 虧 損 狀 態 ， 而 今 年 則 從 原 來 的 55 億 日 元 ( 5600 萬 美 元 ) 虧 損 轉 成 了 26 億 日 元 ( 2600 萬 美 元 ) 的 盈 利 。\n",
      "    Target: 扭 虧 為 盈 [UNK] 上 半 財 年 收 6 . [UNK] 億 美 元\n",
      "    Predict: [UNK] 年 營 收 [UNK] 億 美 元 同 比 增 長 1 %\n",
      "\n",
      "    Input: 網 際 網 路 對 裝 修 使 用 者 的 影 響 ， 造 就 了 網 際 網 路 對 家 居 行 業 的 影 響 。 齊 家 網 做 了 很 多 工 作 。 主 要 分 成 兩 部 分 ： 一 部 分 圍 繞 網 際 網 路 思 維 ， 把 體 驗 、 極 致 、 創 新 做 透 。 第 二 部 分 圍 繞 著 家 居 ， 通 過 團 購 、 商 城 、 體 驗 館 形 成 了 齊 家 2 模 式 。\n",
      "    Target: 2 案 例 : 齊 家 如 何 應 對 2 帶 來 的 家 居 變 革\n",
      "    Predict: 齊 家 網 : 網 際 網 路 + 家 居 + 體 驗 + 創 新 做 透\n",
      "\n",
      "Epoch 00024: val_loss improved from 2.64967 to 2.63045, saving model to /data/Text_Summarizer/models/checkpoints/ZH_BertEncoderTransformer_ckiplab-albert-tiny-chinese_2-6layers_1projlayers_tune0layers_8heads_256embed_512hidden_0.2dropout_gelu_9230tarvocab_0.0005initlr_45310warmup_AdamWeightDecay_64batchsize_8192shuffle_289936samples_100%Teacher/ckpt\n",
      "4531/4531 [==============================] - 1446s 319ms/step - loss: 2.4145 - accuracy: 0.5453 - val_loss: 2.6304 - val_accuracy: 0.5357\n",
      "Epoch 25/100\n",
      "4531/4531 [==============================] - ETA: 0s - loss: 2.3973 - accuracy: 0.5474\n",
      "    Input: 近 日 ， 有 網 友 反 映 ， 黑 龍 江 移 動 公 司 疑 似 私 自 為 客 戶 套 送 增 值 付 費 套 餐 ， 這 些 業 務 並 沒 有 經 過 客 戶 的 主 觀 同 意 。 舉 報 問 題 的 網 友 認 為 ， 其 個 人 資 訊 的 安 全 受 到 了 嚴 重 威 脅 。 對 此 ， 移 動 公 司 表 示 正 在 調 查 ， 並 將 於 14 日 給 出 回 覆 。\n",
      "    Target: 中 移 動 被 爆 私 自 增 減 客 戶 業 務 迴 應 稱 正 調 查\n",
      "    Predict: 黑 龍 江 移 動 公 司 私 自 套 送 套 餐\n",
      "\n",
      "    Input: 截 至 2013 年 9 月 30 日 的 六 個 月 裡 ， 銷 售 收 入 617 億 日 元 ( 6. 26 億 美 元 ) ， 同 比 增 長 1 % 。 然 而 淨 收 入 方 面 的 增 長 更 為 突 出 ， 去 年 同 期 該 公 司 還 處 於 虧 損 狀 態 ， 而 今 年 則 從 原 來 的 55 億 日 元 ( 5600 萬 美 元 ) 虧 損 轉 成 了 26 億 日 元 ( 2600 萬 美 元 ) 的 盈 利 。\n",
      "    Target: 扭 虧 為 盈 [UNK] 上 半 財 年 收 6 . [UNK] 億 美 元\n",
      "    Predict: 去 年 淨 收 入 增 長 突 出\n",
      "\n",
      "    Input: 網 際 網 路 對 裝 修 使 用 者 的 影 響 ， 造 就 了 網 際 網 路 對 家 居 行 業 的 影 響 。 齊 家 網 做 了 很 多 工 作 。 主 要 分 成 兩 部 分 ： 一 部 分 圍 繞 網 際 網 路 思 維 ， 把 體 驗 、 極 致 、 創 新 做 透 。 第 二 部 分 圍 繞 著 家 居 ， 通 過 團 購 、 商 城 、 體 驗 館 形 成 了 齊 家 2 模 式 。\n",
      "    Target: 2 案 例 : 齊 家 如 何 應 對 2 帶 來 的 家 居 變 革\n",
      "    Predict: 齊 家 網 : 網 際 網 路 對 家 居 行 業 影 響\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 2.63045\n",
      "4531/4531 [==============================] - 1443s 319ms/step - loss: 2.3973 - accuracy: 0.5474 - val_loss: 2.6338 - val_accuracy: 0.5367\n",
      "Epoch 26/100\n",
      "4531/4531 [==============================] - ETA: 0s - loss: 2.3801 - accuracy: 0.5496\n",
      "    Input: 近 日 ， 有 網 友 反 映 ， 黑 龍 江 移 動 公 司 疑 似 私 自 為 客 戶 套 送 增 值 付 費 套 餐 ， 這 些 業 務 並 沒 有 經 過 客 戶 的 主 觀 同 意 。 舉 報 問 題 的 網 友 認 為 ， 其 個 人 資 訊 的 安 全 受 到 了 嚴 重 威 脅 。 對 此 ， 移 動 公 司 表 示 正 在 調 查 ， 並 將 於 14 日 給 出 回 覆 。\n",
      "    Target: 中 移 動 被 爆 私 自 增 減 客 戶 業 務 迴 應 稱 正 調 查\n",
      "    Predict: 黑 龍 江 移 動 公 司 私 自 為 客 戶 套 送 增 值 套 餐\n",
      "\n",
      "    Input: 本 以 為 買 的 是 銀 行 理 財 產 品 ， 沒 料 到 卻 是 客 戶 經 理 違 規 代 銷 的 貴 金 屬 產 品 ， 農 行 北 京 分 行 客 戶 張 呈 360 萬 資 金 不 翼 而 飛 。 此 後 ， 理 財 經 理 閃 電 辭 職 ， 農 行 稱 非 銀 行 產 品 拒 絕 承 擔 責 任 。\n",
      "    Target: 農 行 客 戶 [UNK] 萬 遭 遇 飛 單 銀 行 稱 非 銀 行 產 品 不 擔 責 任\n",
      "    Predict: 農 行 理 財 經 理 閃 電 辭 職 非 銀 行 產 品 拒 絕 承 擔 責 任\n",
      "\n",
      "    Input: 最 近 ， 一 款 名 為 雷 達 - 密 碼 破 解 器 的 蹭 網 神 器 在 街 頭 攤 點 上 時 有 出 現 。 商 家 叫 賣 稱 1 其 可 以 獲 取 周 邊 電 腦 網 路 的 - 熱 點 資 訊 ， 並 自 動 破 解 密 碼 ， 終 身 不 用 付 網 費 。 它 其 實 是 一 個 用 供 電 的 的 發 光 二 極 體 。\n",
      "    Target: 榕 街 頭 現 - 密 碼 破 解 器 實 為 地 攤 騙 錢 神 器\n",
      "    Predict: 雷 達 - 密 碼 破 解 器 網 神 器\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 2.63045\n",
      "4531/4531 [==============================] - 1443s 319ms/step - loss: 2.3801 - accuracy: 0.5496 - val_loss: 2.6315 - val_accuracy: 0.5368\n",
      "Epoch 27/100\n",
      "4531/4531 [==============================] - ETA: 0s - loss: 2.3643 - accuracy: 0.5516\n",
      "    Input: 最 近 ， 一 款 名 為 雷 達 - 密 碼 破 解 器 的 蹭 網 神 器 在 街 頭 攤 點 上 時 有 出 現 。 商 家 叫 賣 稱 1 其 可 以 獲 取 周 邊 電 腦 網 路 的 - 熱 點 資 訊 ， 並 自 動 破 解 密 碼 ， 終 身 不 用 付 網 費 。 它 其 實 是 一 個 用 供 電 的 的 發 光 二 極 體 。\n",
      "    Target: 榕 街 頭 現 - 密 碼 破 解 器 實 為 地 攤 騙 錢 神 器\n",
      "    Predict: 雷 達 - 密 碼 破 解 器\n",
      "\n",
      "    Input: 網 際 網 路 對 裝 修 使 用 者 的 影 響 ， 造 就 了 網 際 網 路 對 家 居 行 業 的 影 響 。 齊 家 網 做 了 很 多 工 作 。 主 要 分 成 兩 部 分 ： 一 部 分 圍 繞 網 際 網 路 思 維 ， 把 體 驗 、 極 致 、 創 新 做 透 。 第 二 部 分 圍 繞 著 家 居 ， 通 過 團 購 、 商 城 、 體 驗 館 形 成 了 齊 家 2 模 式 。\n",
      "    Target: 2 案 例 : 齊 家 如 何 應 對 2 帶 來 的 家 居 變 革\n",
      "    Predict: 齊 家 網 : 網 際 網 路 對 裝 修 使 用 者 影 響\n",
      "\n",
      "    Input: 本 以 為 買 的 是 銀 行 理 財 產 品 ， 沒 料 到 卻 是 客 戶 經 理 違 規 代 銷 的 貴 金 屬 產 品 ， 農 行 北 京 分 行 客 戶 張 呈 360 萬 資 金 不 翼 而 飛 。 此 後 ， 理 財 經 理 閃 電 辭 職 ， 農 行 稱 非 銀 行 產 品 拒 絕 承 擔 責 任 。\n",
      "    Target: 農 行 客 戶 [UNK] 萬 遭 遇 飛 單 銀 行 稱 非 銀 行 產 品 不 擔 責 任\n",
      "    Predict: 農 行 理 財 經 理 閃 電 辭 職 非 銀 行 產 品 拒 絕 承 擔 責 任\n",
      "\n",
      "Epoch 00027: val_loss improved from 2.63045 to 2.62607, saving model to /data/Text_Summarizer/models/checkpoints/ZH_BertEncoderTransformer_ckiplab-albert-tiny-chinese_2-6layers_1projlayers_tune0layers_8heads_256embed_512hidden_0.2dropout_gelu_9230tarvocab_0.0005initlr_45310warmup_AdamWeightDecay_64batchsize_8192shuffle_289936samples_100%Teacher/ckpt\n",
      "4531/4531 [==============================] - 1446s 319ms/step - loss: 2.3643 - accuracy: 0.5516 - val_loss: 2.6261 - val_accuracy: 0.5395\n",
      "Epoch 28/100\n",
      "4531/4531 [==============================] - ETA: 0s - loss: 2.3485 - accuracy: 0.5536\n",
      "    Input: 近 日 ， 有 網 友 反 映 ， 黑 龍 江 移 動 公 司 疑 似 私 自 為 客 戶 套 送 增 值 付 費 套 餐 ， 這 些 業 務 並 沒 有 經 過 客 戶 的 主 觀 同 意 。 舉 報 問 題 的 網 友 認 為 ， 其 個 人 資 訊 的 安 全 受 到 了 嚴 重 威 脅 。 對 此 ， 移 動 公 司 表 示 正 在 調 查 ， 並 將 於 14 日 給 出 回 覆 。\n",
      "    Target: 中 移 動 被 爆 私 自 增 減 客 戶 業 務 迴 應 稱 正 調 查\n",
      "    Predict: 黑 龍 江 移 動 公 司 私 套 送 增 值 付 費 套 餐\n",
      "\n",
      "    Input: 截 至 2013 年 9 月 30 日 的 六 個 月 裡 ， 銷 售 收 入 617 億 日 元 ( 6. 26 億 美 元 ) ， 同 比 增 長 1 % 。 然 而 淨 收 入 方 面 的 增 長 更 為 突 出 ， 去 年 同 期 該 公 司 還 處 於 虧 損 狀 態 ， 而 今 年 則 從 原 來 的 55 億 日 元 ( 5600 萬 美 元 ) 虧 損 轉 成 了 26 億 日 元 ( 2600 萬 美 元 ) 的 盈 利 。\n",
      "    Target: 扭 虧 為 盈 [UNK] 上 半 財 年 收 6 . [UNK] 億 美 元\n",
      "    Predict: 日 本 去 年 虧 損 [UNK] 萬 美 元\n",
      "\n",
      "    Input: 本 以 為 買 的 是 銀 行 理 財 產 品 ， 沒 料 到 卻 是 客 戶 經 理 違 規 代 銷 的 貴 金 屬 產 品 ， 農 行 北 京 分 行 客 戶 張 呈 360 萬 資 金 不 翼 而 飛 。 此 後 ， 理 財 經 理 閃 電 辭 職 ， 農 行 稱 非 銀 行 產 品 拒 絕 承 擔 責 任 。\n",
      "    Target: 農 行 客 戶 [UNK] 萬 遭 遇 飛 單 銀 行 稱 非 銀 行 產 品 不 擔 責 任\n",
      "    Predict: 農 行 理 財 經 理 閃 電 辭 職 : 非 銀 行 產 品 拒 絕 承 擔 責 任\n",
      "\n",
      "Epoch 00028: val_loss improved from 2.62607 to 2.61897, saving model to /data/Text_Summarizer/models/checkpoints/ZH_BertEncoderTransformer_ckiplab-albert-tiny-chinese_2-6layers_1projlayers_tune0layers_8heads_256embed_512hidden_0.2dropout_gelu_9230tarvocab_0.0005initlr_45310warmup_AdamWeightDecay_64batchsize_8192shuffle_289936samples_100%Teacher/ckpt\n",
      "4531/4531 [==============================] - 1446s 319ms/step - loss: 2.3485 - accuracy: 0.5536 - val_loss: 2.6190 - val_accuracy: 0.5382\n",
      "Epoch 29/100\n",
      "4531/4531 [==============================] - ETA: 0s - loss: 2.3336 - accuracy: 0.5555\n",
      "    Input: 截 至 2013 年 9 月 30 日 的 六 個 月 裡 ， 銷 售 收 入 617 億 日 元 ( 6. 26 億 美 元 ) ， 同 比 增 長 1 % 。 然 而 淨 收 入 方 面 的 增 長 更 為 突 出 ， 去 年 同 期 該 公 司 還 處 於 虧 損 狀 態 ， 而 今 年 則 從 原 來 的 55 億 日 元 ( 5600 萬 美 元 ) 虧 損 轉 成 了 26 億 日 元 ( 2600 萬 美 元 ) 的 盈 利 。\n",
      "    Target: 扭 虧 為 盈 [UNK] 上 半 財 年 收 6 . [UNK] 億 美 元\n",
      "    Predict: 6 個 月 銷 售 收 入 6 . [UNK] 億 美 元 同 比 增 長 1 %\n",
      "\n",
      "    Input: 近 日 ， 有 網 友 反 映 ， 黑 龍 江 移 動 公 司 疑 似 私 自 為 客 戶 套 送 增 值 付 費 套 餐 ， 這 些 業 務 並 沒 有 經 過 客 戶 的 主 觀 同 意 。 舉 報 問 題 的 網 友 認 為 ， 其 個 人 資 訊 的 安 全 受 到 了 嚴 重 威 脅 。 對 此 ， 移 動 公 司 表 示 正 在 調 查 ， 並 將 於 14 日 給 出 回 覆 。\n",
      "    Target: 中 移 動 被 爆 私 自 增 減 客 戶 業 務 迴 應 稱 正 調 查\n",
      "    Predict: 黑 龍 江 移 動 公 司 私 自 為 客 戶 套 送 增 值 套 餐\n",
      "\n",
      "    Input: 網 際 網 路 對 裝 修 使 用 者 的 影 響 ， 造 就 了 網 際 網 路 對 家 居 行 業 的 影 響 。 齊 家 網 做 了 很 多 工 作 。 主 要 分 成 兩 部 分 ： 一 部 分 圍 繞 網 際 網 路 思 維 ， 把 體 驗 、 極 致 、 創 新 做 透 。 第 二 部 分 圍 繞 著 家 居 ， 通 過 團 購 、 商 城 、 體 驗 館 形 成 了 齊 家 2 模 式 。\n",
      "    Target: 2 案 例 : 齊 家 如 何 應 對 2 帶 來 的 家 居 變 革\n",
      "    Predict: 齊 家 網 : 網 際 網 路 對 裝 修 影 響\n",
      "\n",
      "Epoch 00029: val_loss improved from 2.61897 to 2.61464, saving model to /data/Text_Summarizer/models/checkpoints/ZH_BertEncoderTransformer_ckiplab-albert-tiny-chinese_2-6layers_1projlayers_tune0layers_8heads_256embed_512hidden_0.2dropout_gelu_9230tarvocab_0.0005initlr_45310warmup_AdamWeightDecay_64batchsize_8192shuffle_289936samples_100%Teacher/ckpt\n",
      "4531/4531 [==============================] - 1445s 319ms/step - loss: 2.3336 - accuracy: 0.5555 - val_loss: 2.6146 - val_accuracy: 0.5400\n",
      "Epoch 30/100\n",
      "4531/4531 [==============================] - ETA: 0s - loss: 2.3190 - accuracy: 0.5576\n",
      "    Input: 近 日 ， 有 網 友 反 映 ， 黑 龍 江 移 動 公 司 疑 似 私 自 為 客 戶 套 送 增 值 付 費 套 餐 ， 這 些 業 務 並 沒 有 經 過 客 戶 的 主 觀 同 意 。 舉 報 問 題 的 網 友 認 為 ， 其 個 人 資 訊 的 安 全 受 到 了 嚴 重 威 脅 。 對 此 ， 移 動 公 司 表 示 正 在 調 查 ， 並 將 於 14 日 給 出 回 覆 。\n",
      "    Target: 中 移 動 被 爆 私 自 增 減 客 戶 業 務 迴 應 稱 正 調 查\n",
      "    Predict: 黑 龍 江 移 動 否 認 私 自 為 客 戶 套 送 增 值 套 餐\n",
      "\n",
      "    Input: 截 至 2013 年 9 月 30 日 的 六 個 月 裡 ， 銷 售 收 入 617 億 日 元 ( 6. 26 億 美 元 ) ， 同 比 增 長 1 % 。 然 而 淨 收 入 方 面 的 增 長 更 為 突 出 ， 去 年 同 期 該 公 司 還 處 於 虧 損 狀 態 ， 而 今 年 則 從 原 來 的 55 億 日 元 ( 5600 萬 美 元 ) 虧 損 轉 成 了 26 億 日 元 ( 2600 萬 美 元 ) 的 盈 利 。\n",
      "    Target: 扭 虧 為 盈 [UNK] 上 半 財 年 收 6 . [UNK] 億 美 元\n",
      "    Predict: 6 個 月 虧 損 [UNK] 萬 美 元\n",
      "\n",
      "    Input: 網 際 網 路 對 裝 修 使 用 者 的 影 響 ， 造 就 了 網 際 網 路 對 家 居 行 業 的 影 響 。 齊 家 網 做 了 很 多 工 作 。 主 要 分 成 兩 部 分 ： 一 部 分 圍 繞 網 際 網 路 思 維 ， 把 體 驗 、 極 致 、 創 新 做 透 。 第 二 部 分 圍 繞 著 家 居 ， 通 過 團 購 、 商 城 、 體 驗 館 形 成 了 齊 家 2 模 式 。\n",
      "    Target: 2 案 例 : 齊 家 如 何 應 對 2 帶 來 的 家 居 變 革\n",
      "    Predict: 齊 家 網 : 網 際 網 路 對 裝 修 影 響 的 影 響\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 2.61464\n",
      "4531/4531 [==============================] - 1442s 318ms/step - loss: 2.3190 - accuracy: 0.5576 - val_loss: 2.6252 - val_accuracy: 0.5393\n",
      "Epoch 31/100\n",
      "4531/4531 [==============================] - ETA: 0s - loss: 2.3048 - accuracy: 0.5594\n",
      "    Input: 近 日 ， 有 網 友 反 映 ， 黑 龍 江 移 動 公 司 疑 似 私 自 為 客 戶 套 送 增 值 付 費 套 餐 ， 這 些 業 務 並 沒 有 經 過 客 戶 的 主 觀 同 意 。 舉 報 問 題 的 網 友 認 為 ， 其 個 人 資 訊 的 安 全 受 到 了 嚴 重 威 脅 。 對 此 ， 移 動 公 司 表 示 正 在 調 查 ， 並 將 於 14 日 給 出 回 覆 。\n",
      "    Target: 中 移 動 被 爆 私 自 增 減 客 戶 業 務 迴 應 稱 正 調 查\n",
      "    Predict: 黑 龍 江 移 動 公 司 私 自 套 送 增 值 套 餐\n",
      "\n",
      "    Input: 網 際 網 路 對 裝 修 使 用 者 的 影 響 ， 造 就 了 網 際 網 路 對 家 居 行 業 的 影 響 。 齊 家 網 做 了 很 多 工 作 。 主 要 分 成 兩 部 分 ： 一 部 分 圍 繞 網 際 網 路 思 維 ， 把 體 驗 、 極 致 、 創 新 做 透 。 第 二 部 分 圍 繞 著 家 居 ， 通 過 團 購 、 商 城 、 體 驗 館 形 成 了 齊 家 2 模 式 。\n",
      "    Target: 2 案 例 : 齊 家 如 何 應 對 2 帶 來 的 家 居 變 革\n",
      "    Predict: 齊 家 2 : 網 際 網 路 對 裝 修 影 響 的 影 響\n",
      "\n",
      "    Input: 在 上 海 自 貿 試 驗 區 的 示 範 效 應 下 ， 近 鄰 杭 州 試 圖 另 闢 蹊 徑 ， 主 攻 網 上 自 貿 試 驗 區 。 發 展 方 向 可 能 是 杭 州 正 全 力 試 點 的 跨 境 電 子 商 務 的 升 級 版 ， 提 法 已 引 起 國 家 相 關 部 委 高 度 重 視 ， 國 家 發 改 委 已 要 求 杭 州 儘 快 形 成 方 案 上 報 。\n",
      "    Target: 杭 州 網 上 自 貿 區 設 想 獲 認 可 發 改 委 要 求 上 報 方 案\n",
      "    Predict: 杭 州 試 點 跨 境 電 子 商 務 升 級 版\n",
      "\n",
      "Epoch 00031: val_loss improved from 2.61464 to 2.60692, saving model to /data/Text_Summarizer/models/checkpoints/ZH_BertEncoderTransformer_ckiplab-albert-tiny-chinese_2-6layers_1projlayers_tune0layers_8heads_256embed_512hidden_0.2dropout_gelu_9230tarvocab_0.0005initlr_45310warmup_AdamWeightDecay_64batchsize_8192shuffle_289936samples_100%Teacher/ckpt\n",
      "4531/4531 [==============================] - 1444s 319ms/step - loss: 2.3048 - accuracy: 0.5594 - val_loss: 2.6069 - val_accuracy: 0.5396\n",
      "Epoch 32/100\n",
      "4531/4531 [==============================] - ETA: 0s - loss: 2.2905 - accuracy: 0.5612\n",
      "    Input: 近 日 ， 有 網 友 反 映 ， 黑 龍 江 移 動 公 司 疑 似 私 自 為 客 戶 套 送 增 值 付 費 套 餐 ， 這 些 業 務 並 沒 有 經 過 客 戶 的 主 觀 同 意 。 舉 報 問 題 的 網 友 認 為 ， 其 個 人 資 訊 的 安 全 受 到 了 嚴 重 威 脅 。 對 此 ， 移 動 公 司 表 示 正 在 調 查 ， 並 將 於 14 日 給 出 回 覆 。\n",
      "    Target: 中 移 動 被 爆 私 自 增 減 客 戶 業 務 迴 應 稱 正 調 查\n",
      "    Predict: 黑 龍 江 移 動 疑 套 送 付 費 套 餐 迴 應 稱 正 調 查\n",
      "\n",
      "    Input: 網 際 網 路 對 裝 修 使 用 者 的 影 響 ， 造 就 了 網 際 網 路 對 家 居 行 業 的 影 響 。 齊 家 網 做 了 很 多 工 作 。 主 要 分 成 兩 部 分 ： 一 部 分 圍 繞 網 際 網 路 思 維 ， 把 體 驗 、 極 致 、 創 新 做 透 。 第 二 部 分 圍 繞 著 家 居 ， 通 過 團 購 、 商 城 、 體 驗 館 形 成 了 齊 家 2 模 式 。\n",
      "    Target: 2 案 例 : 齊 家 如 何 應 對 2 帶 來 的 家 居 變 革\n",
      "    Predict: 齊 家 網 : 網 際 網 路 對 裝 修 使 用 者 影 響\n",
      "\n",
      "    Input: 截 至 2013 年 9 月 30 日 的 六 個 月 裡 ， 銷 售 收 入 617 億 日 元 ( 6. 26 億 美 元 ) ， 同 比 增 長 1 % 。 然 而 淨 收 入 方 面 的 增 長 更 為 突 出 ， 去 年 同 期 該 公 司 還 處 於 虧 損 狀 態 ， 而 今 年 則 從 原 來 的 55 億 日 元 ( 5600 萬 美 元 ) 虧 損 轉 成 了 26 億 日 元 ( 2600 萬 美 元 ) 的 盈 利 。\n",
      "    Target: 扭 虧 為 盈 [UNK] 上 半 財 年 收 6 . [UNK] 億 美 元\n",
      "    Predict: 日 本 去 年 虧 損 [UNK] 萬 美 元\n",
      "\n",
      "Epoch 00032: val_loss improved from 2.60692 to 2.60677, saving model to /data/Text_Summarizer/models/checkpoints/ZH_BertEncoderTransformer_ckiplab-albert-tiny-chinese_2-6layers_1projlayers_tune0layers_8heads_256embed_512hidden_0.2dropout_gelu_9230tarvocab_0.0005initlr_45310warmup_AdamWeightDecay_64batchsize_8192shuffle_289936samples_100%Teacher/ckpt\n",
      "4531/4531 [==============================] - 1444s 319ms/step - loss: 2.2905 - accuracy: 0.5612 - val_loss: 2.6068 - val_accuracy: 0.5420\n",
      "Epoch 33/100\n",
      "4531/4531 [==============================] - ETA: 0s - loss: 2.2778 - accuracy: 0.5625\n",
      "    Input: 網 際 網 路 對 裝 修 使 用 者 的 影 響 ， 造 就 了 網 際 網 路 對 家 居 行 業 的 影 響 。 齊 家 網 做 了 很 多 工 作 。 主 要 分 成 兩 部 分 ： 一 部 分 圍 繞 網 際 網 路 思 維 ， 把 體 驗 、 極 致 、 創 新 做 透 。 第 二 部 分 圍 繞 著 家 居 ， 通 過 團 購 、 商 城 、 體 驗 館 形 成 了 齊 家 2 模 式 。\n",
      "    Target: 2 案 例 : 齊 家 如 何 應 對 2 帶 來 的 家 居 變 革\n",
      "    Predict: 齊 家 網 : 網 際 網 路 對 家 居 行 業 的 影 響\n",
      "\n",
      "    Input: 近 日 ， 有 網 友 反 映 ， 黑 龍 江 移 動 公 司 疑 似 私 自 為 客 戶 套 送 增 值 付 費 套 餐 ， 這 些 業 務 並 沒 有 經 過 客 戶 的 主 觀 同 意 。 舉 報 問 題 的 網 友 認 為 ， 其 個 人 資 訊 的 安 全 受 到 了 嚴 重 威 脅 。 對 此 ， 移 動 公 司 表 示 正 在 調 查 ， 並 將 於 14 日 給 出 回 覆 。\n",
      "    Target: 中 移 動 被 爆 私 自 增 減 客 戶 業 務 迴 應 稱 正 調 查\n",
      "    Predict: 黑 龍 江 移 動 否 認 私 自 套 送 增 值 付 費 套 餐\n",
      "\n",
      "    Input: 截 至 2013 年 9 月 30 日 的 六 個 月 裡 ， 銷 售 收 入 617 億 日 元 ( 6. 26 億 美 元 ) ， 同 比 增 長 1 % 。 然 而 淨 收 入 方 面 的 增 長 更 為 突 出 ， 去 年 同 期 該 公 司 還 處 於 虧 損 狀 態 ， 而 今 年 則 從 原 來 的 55 億 日 元 ( 5600 萬 美 元 ) 虧 損 轉 成 了 26 億 日 元 ( 2600 萬 美 元 ) 的 盈 利 。\n",
      "    Target: 扭 虧 為 盈 [UNK] 上 半 財 年 收 6 . [UNK] 億 美 元\n",
      "    Predict: 日 本 去 年 淨 收 6 . [UNK] 億 美 元 同 比 增 長 1 %\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 2.60677\n",
      "4531/4531 [==============================] - 1442s 318ms/step - loss: 2.2778 - accuracy: 0.5625 - val_loss: 2.6113 - val_accuracy: 0.5411\n",
      "Epoch 34/100\n",
      "4531/4531 [==============================] - ETA: 0s - loss: 2.2645 - accuracy: 0.5645\n",
      "    Input: 近 日 ， 有 網 友 反 映 ， 黑 龍 江 移 動 公 司 疑 似 私 自 為 客 戶 套 送 增 值 付 費 套 餐 ， 這 些 業 務 並 沒 有 經 過 客 戶 的 主 觀 同 意 。 舉 報 問 題 的 網 友 認 為 ， 其 個 人 資 訊 的 安 全 受 到 了 嚴 重 威 脅 。 對 此 ， 移 動 公 司 表 示 正 在 調 查 ， 並 將 於 14 日 給 出 回 覆 。\n",
      "    Target: 中 移 動 被 爆 私 自 增 減 客 戶 業 務 迴 應 稱 正 調 查\n",
      "    Predict: 黑 龍 江 移 動 否 認 套 送 付 費 套 餐 : 正 調 查\n",
      "\n",
      "    Input: 截 至 2013 年 9 月 30 日 的 六 個 月 裡 ， 銷 售 收 入 617 億 日 元 ( 6. 26 億 美 元 ) ， 同 比 增 長 1 % 。 然 而 淨 收 入 方 面 的 增 長 更 為 突 出 ， 去 年 同 期 該 公 司 還 處 於 虧 損 狀 態 ， 而 今 年 則 從 原 來 的 55 億 日 元 ( 5600 萬 美 元 ) 虧 損 轉 成 了 26 億 日 元 ( 2600 萬 美 元 ) 的 盈 利 。\n",
      "    Target: 扭 虧 為 盈 [UNK] 上 半 財 年 收 6 . [UNK] 億 美 元\n",
      "    Predict: 6 個 月 銷 售 收 入 同 比 增 長 1 %\n",
      "\n",
      "    Input: 網 際 網 路 對 裝 修 使 用 者 的 影 響 ， 造 就 了 網 際 網 路 對 家 居 行 業 的 影 響 。 齊 家 網 做 了 很 多 工 作 。 主 要 分 成 兩 部 分 ： 一 部 分 圍 繞 網 際 網 路 思 維 ， 把 體 驗 、 極 致 、 創 新 做 透 。 第 二 部 分 圍 繞 著 家 居 ， 通 過 團 購 、 商 城 、 體 驗 館 形 成 了 齊 家 2 模 式 。\n",
      "    Target: 2 案 例 : 齊 家 如 何 應 對 2 帶 來 的 家 居 變 革\n",
      "    Predict: 齊 家 網 : 網 際 網 路 + 團 購 、 體 驗 館\n",
      "\n",
      "Epoch 00034: val_loss improved from 2.60677 to 2.60039, saving model to /data/Text_Summarizer/models/checkpoints/ZH_BertEncoderTransformer_ckiplab-albert-tiny-chinese_2-6layers_1projlayers_tune0layers_8heads_256embed_512hidden_0.2dropout_gelu_9230tarvocab_0.0005initlr_45310warmup_AdamWeightDecay_64batchsize_8192shuffle_289936samples_100%Teacher/ckpt\n",
      "4531/4531 [==============================] - 1445s 319ms/step - loss: 2.2645 - accuracy: 0.5645 - val_loss: 2.6004 - val_accuracy: 0.5413\n",
      "Epoch 35/100\n",
      "4531/4531 [==============================] - ETA: 0s - loss: 2.2509 - accuracy: 0.5665\n",
      "    Input: 近 日 ， 有 網 友 反 映 ， 黑 龍 江 移 動 公 司 疑 似 私 自 為 客 戶 套 送 增 值 付 費 套 餐 ， 這 些 業 務 並 沒 有 經 過 客 戶 的 主 觀 同 意 。 舉 報 問 題 的 網 友 認 為 ， 其 個 人 資 訊 的 安 全 受 到 了 嚴 重 威 脅 。 對 此 ， 移 動 公 司 表 示 正 在 調 查 ， 並 將 於 14 日 給 出 回 覆 。\n",
      "    Target: 中 移 動 被 爆 私 自 增 減 客 戶 業 務 迴 應 稱 正 調 查\n",
      "    Predict: 黑 龍 江 移 動 否 認 私 自 為 客 戶 套 送 增 值 付 費 套 餐\n",
      "\n",
      "    Input: 截 至 2013 年 9 月 30 日 的 六 個 月 裡 ， 銷 售 收 入 617 億 日 元 ( 6. 26 億 美 元 ) ， 同 比 增 長 1 % 。 然 而 淨 收 入 方 面 的 增 長 更 為 突 出 ， 去 年 同 期 該 公 司 還 處 於 虧 損 狀 態 ， 而 今 年 則 從 原 來 的 55 億 日 元 ( 5600 萬 美 元 ) 虧 損 轉 成 了 26 億 日 元 ( 2600 萬 美 元 ) 的 盈 利 。\n",
      "    Target: 扭 虧 為 盈 [UNK] 上 半 財 年 收 6 . [UNK] 億 美 元\n",
      "    Predict: 日 本 6 個 月 銷 售 收 入 同 比 增 長 1 %\n",
      "\n",
      "    Input: 網 際 網 路 對 裝 修 使 用 者 的 影 響 ， 造 就 了 網 際 網 路 對 家 居 行 業 的 影 響 。 齊 家 網 做 了 很 多 工 作 。 主 要 分 成 兩 部 分 ： 一 部 分 圍 繞 網 際 網 路 思 維 ， 把 體 驗 、 極 致 、 創 新 做 透 。 第 二 部 分 圍 繞 著 家 居 ， 通 過 團 購 、 商 城 、 體 驗 館 形 成 了 齊 家 2 模 式 。\n",
      "    Target: 2 案 例 : 齊 家 如 何 應 對 2 帶 來 的 家 居 變 革\n",
      "    Predict: 齊 家 網 : 網 際 網 路 + 團 購 、 體 驗 館\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 2.60039\n",
      "4531/4531 [==============================] - 1443s 318ms/step - loss: 2.2509 - accuracy: 0.5665 - val_loss: 2.6220 - val_accuracy: 0.5424\n",
      "Epoch 36/100\n",
      "4531/4531 [==============================] - ETA: 0s - loss: 2.2392 - accuracy: 0.5682\n",
      "    Input: 近 日 ， 有 網 友 反 映 ， 黑 龍 江 移 動 公 司 疑 似 私 自 為 客 戶 套 送 增 值 付 費 套 餐 ， 這 些 業 務 並 沒 有 經 過 客 戶 的 主 觀 同 意 。 舉 報 問 題 的 網 友 認 為 ， 其 個 人 資 訊 的 安 全 受 到 了 嚴 重 威 脅 。 對 此 ， 移 動 公 司 表 示 正 在 調 查 ， 並 將 於 14 日 給 出 回 覆 。\n",
      "    Target: 中 移 動 被 爆 私 自 增 減 客 戶 業 務 迴 應 稱 正 調 查\n",
      "    Predict: 黑 龍 江 移 動 疑 為 客 戶 套 送 套 餐 迴 應 稱 正 調 查\n",
      "\n",
      "    Input: 截 至 2013 年 9 月 30 日 的 六 個 月 裡 ， 銷 售 收 入 617 億 日 元 ( 6. 26 億 美 元 ) ， 同 比 增 長 1 % 。 然 而 淨 收 入 方 面 的 增 長 更 為 突 出 ， 去 年 同 期 該 公 司 還 處 於 虧 損 狀 態 ， 而 今 年 則 從 原 來 的 55 億 日 元 ( 5600 萬 美 元 ) 虧 損 轉 成 了 26 億 日 元 ( 2600 萬 美 元 ) 的 盈 利 。\n",
      "    Target: 扭 虧 為 盈 [UNK] 上 半 財 年 收 6 . [UNK] 億 美 元\n",
      "    Predict: 日 本 去 年 淨 收 入 增 長 突 出 虧 損 [UNK] 億 美 元\n",
      "\n",
      "    Input: 網 際 網 路 對 裝 修 使 用 者 的 影 響 ， 造 就 了 網 際 網 路 對 家 居 行 業 的 影 響 。 齊 家 網 做 了 很 多 工 作 。 主 要 分 成 兩 部 分 ： 一 部 分 圍 繞 網 際 網 路 思 維 ， 把 體 驗 、 極 致 、 創 新 做 透 。 第 二 部 分 圍 繞 著 家 居 ， 通 過 團 購 、 商 城 、 體 驗 館 形 成 了 齊 家 2 模 式 。\n",
      "    Target: 2 案 例 : 齊 家 如 何 應 對 2 帶 來 的 家 居 變 革\n",
      "    Predict: 齊 家 網 : 網 際 網 路 + 團 購 、 體 驗 館\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 2.60039\n",
      "4531/4531 [==============================] - 1443s 318ms/step - loss: 2.2392 - accuracy: 0.5682 - val_loss: 2.6108 - val_accuracy: 0.5423\n",
      "Epoch 37/100\n",
      "4531/4531 [==============================] - ETA: 0s - loss: 2.2267 - accuracy: 0.5695\n",
      "    Input: 近 日 ， 有 網 友 反 映 ， 黑 龍 江 移 動 公 司 疑 似 私 自 為 客 戶 套 送 增 值 付 費 套 餐 ， 這 些 業 務 並 沒 有 經 過 客 戶 的 主 觀 同 意 。 舉 報 問 題 的 網 友 認 為 ， 其 個 人 資 訊 的 安 全 受 到 了 嚴 重 威 脅 。 對 此 ， 移 動 公 司 表 示 正 在 調 查 ， 並 將 於 14 日 給 出 回 覆 。\n",
      "    Target: 中 移 動 被 爆 私 自 增 減 客 戶 業 務 迴 應 稱 正 調 查\n",
      "    Predict: 黑 龍 江 移 動 疑 為 客 戶 套 送 套 餐 迴 應 稱 正 調 查\n",
      "\n",
      "    Input: 網 際 網 路 對 裝 修 使 用 者 的 影 響 ， 造 就 了 網 際 網 路 對 家 居 行 業 的 影 響 。 齊 家 網 做 了 很 多 工 作 。 主 要 分 成 兩 部 分 ： 一 部 分 圍 繞 網 際 網 路 思 維 ， 把 體 驗 、 極 致 、 創 新 做 透 。 第 二 部 分 圍 繞 著 家 居 ， 通 過 團 購 、 商 城 、 體 驗 館 形 成 了 齊 家 2 模 式 。\n",
      "    Target: 2 案 例 : 齊 家 如 何 應 對 2 帶 來 的 家 居 變 革\n",
      "    Predict: 齊 家 網 : 網 際 網 路 對 裝 修 影 響 的 影 響\n",
      "\n",
      "    Input: 最 近 ， 一 款 名 為 雷 達 - 密 碼 破 解 器 的 蹭 網 神 器 在 街 頭 攤 點 上 時 有 出 現 。 商 家 叫 賣 稱 1 其 可 以 獲 取 周 邊 電 腦 網 路 的 - 熱 點 資 訊 ， 並 自 動 破 解 密 碼 ， 終 身 不 用 付 網 費 。 它 其 實 是 一 個 用 供 電 的 的 發 光 二 極 體 。\n",
      "    Target: 榕 街 頭 現 - 密 碼 破 解 器 實 為 地 攤 騙 錢 神 器\n",
      "    Predict: 雷 達 - 密 碼 破 解 器 出 現\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 2.60039\n",
      "4531/4531 [==============================] - 1443s 318ms/step - loss: 2.2267 - accuracy: 0.5695 - val_loss: 2.6220 - val_accuracy: 0.5441\n",
      "Epoch 38/100\n",
      "4531/4531 [==============================] - ETA: 0s - loss: 2.2139 - accuracy: 0.5713\n",
      "    Input: 近 日 ， 有 網 友 反 映 ， 黑 龍 江 移 動 公 司 疑 似 私 自 為 客 戶 套 送 增 值 付 費 套 餐 ， 這 些 業 務 並 沒 有 經 過 客 戶 的 主 觀 同 意 。 舉 報 問 題 的 網 友 認 為 ， 其 個 人 資 訊 的 安 全 受 到 了 嚴 重 威 脅 。 對 此 ， 移 動 公 司 表 示 正 在 調 查 ， 並 將 於 14 日 給 出 回 覆 。\n",
      "    Target: 中 移 動 被 爆 私 自 增 減 客 戶 業 務 迴 應 稱 正 調 查\n",
      "    Predict: 黑 龍 江 移 動 否 認 私 自 為 客 戶 套 送 增 值 付 費 套 餐\n",
      "\n",
      "    Input: 截 至 2013 年 9 月 30 日 的 六 個 月 裡 ， 銷 售 收 入 617 億 日 元 ( 6. 26 億 美 元 ) ， 同 比 增 長 1 % 。 然 而 淨 收 入 方 面 的 增 長 更 為 突 出 ， 去 年 同 期 該 公 司 還 處 於 虧 損 狀 態 ， 而 今 年 則 從 原 來 的 55 億 日 元 ( 5600 萬 美 元 ) 虧 損 轉 成 了 26 億 日 元 ( 2600 萬 美 元 ) 的 盈 利 。\n",
      "    Target: 扭 虧 為 盈 [UNK] 上 半 財 年 收 6 . [UNK] 億 美 元\n",
      "    Predict: 六 個 月 淨 收 入 同 比 增 長 1 %\n",
      "\n",
      "    Input: 網 際 網 路 對 裝 修 使 用 者 的 影 響 ， 造 就 了 網 際 網 路 對 家 居 行 業 的 影 響 。 齊 家 網 做 了 很 多 工 作 。 主 要 分 成 兩 部 分 ： 一 部 分 圍 繞 網 際 網 路 思 維 ， 把 體 驗 、 極 致 、 創 新 做 透 。 第 二 部 分 圍 繞 著 家 居 ， 通 過 團 購 、 商 城 、 體 驗 館 形 成 了 齊 家 2 模 式 。\n",
      "    Target: 2 案 例 : 齊 家 如 何 應 對 2 帶 來 的 家 居 變 革\n",
      "    Predict: 齊 家 網 : 把 體 驗 、 極 致 、 創 新 做 透\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 2.60039\n",
      "4531/4531 [==============================] - 1443s 318ms/step - loss: 2.2139 - accuracy: 0.5713 - val_loss: 2.6194 - val_accuracy: 0.5420\n",
      "Epoch 39/100\n",
      "4531/4531 [==============================] - ETA: 0s - loss: 2.2029 - accuracy: 0.5726\n",
      "    Input: 近 日 ， 有 網 友 反 映 ， 黑 龍 江 移 動 公 司 疑 似 私 自 為 客 戶 套 送 增 值 付 費 套 餐 ， 這 些 業 務 並 沒 有 經 過 客 戶 的 主 觀 同 意 。 舉 報 問 題 的 網 友 認 為 ， 其 個 人 資 訊 的 安 全 受 到 了 嚴 重 威 脅 。 對 此 ， 移 動 公 司 表 示 正 在 調 查 ， 並 將 於 14 日 給 出 回 覆 。\n",
      "    Target: 中 移 動 被 爆 私 自 增 減 客 戶 業 務 迴 應 稱 正 調 查\n",
      "    Predict: 黑 龍 江 移 動 疑 為 客 戶 套 送 增 值 付 費 套 餐\n",
      "\n",
      "    Input: 截 至 2013 年 9 月 30 日 的 六 個 月 裡 ， 銷 售 收 入 617 億 日 元 ( 6. 26 億 美 元 ) ， 同 比 增 長 1 % 。 然 而 淨 收 入 方 面 的 增 長 更 為 突 出 ， 去 年 同 期 該 公 司 還 處 於 虧 損 狀 態 ， 而 今 年 則 從 原 來 的 55 億 日 元 ( 5600 萬 美 元 ) 虧 損 轉 成 了 26 億 日 元 ( 2600 萬 美 元 ) 的 盈 利 。\n",
      "    Target: 扭 虧 為 盈 [UNK] 上 半 財 年 收 6 . [UNK] 億 美 元\n",
      "    Predict: 日 本 公 司 去 年 虧 損 [UNK] 萬 美 元\n",
      "\n",
      "    Input: 網 際 網 路 對 裝 修 使 用 者 的 影 響 ， 造 就 了 網 際 網 路 對 家 居 行 業 的 影 響 。 齊 家 網 做 了 很 多 工 作 。 主 要 分 成 兩 部 分 ： 一 部 分 圍 繞 網 際 網 路 思 維 ， 把 體 驗 、 極 致 、 創 新 做 透 。 第 二 部 分 圍 繞 著 家 居 ， 通 過 團 購 、 商 城 、 體 驗 館 形 成 了 齊 家 2 模 式 。\n",
      "    Target: 2 案 例 : 齊 家 如 何 應 對 2 帶 來 的 家 居 變 革\n",
      "    Predict: 齊 家 網 : 網 際 網 路 + 家 居\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 2.60039\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "4531/4531 [==============================] - 1442s 318ms/step - loss: 2.2029 - accuracy: 0.5726 - val_loss: 2.6138 - val_accuracy: 0.5443\n",
      "Epoch 00039: early stopping\n",
      "CPU times: user 8h 50min 11s, sys: 2h 6min 42s, total: 10h 56min 53s\n",
      "Wall time: 15h 40min 32s\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### <b> Evaluation <b/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "78it [15:15, 11.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Score: rouge-0.314779\n",
      "CPU times: user 14min 56s, sys: 1.28 s, total: 14min 58s\n",
      "Wall time: 15min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "### measure the performance\n",
    "\n",
    "for dataset in tqdm.tqdm(test_batches):\n",
    "    inp_list, tar_list, pred_list = predict_step(model, dataset)\n",
    "\n",
    "if 'bleu' in score_name:\n",
    "    text_scores = text_metric.compute(lowercase=True)\n",
    "    text_score = text_scores['score']\n",
    "elif 'rouge' in score_name:\n",
    "    text_scores = text_metric.compute()\n",
    "    text_score = text_scores['rouge1'].mid.fmeasure\n",
    "\n",
    "score = f\"{score_name}-{text_score:.6f}\"\n",
    "print('\\nModel Score:', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### <b> Export <b/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-03 14:45:11.336734: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "WARNING:absl:Found untraced functions such as dense_layer_call_fn, dense_layer_call_and_return_conditional_losses, activation_layer_call_fn, activation_layer_call_and_return_conditional_losses, dropout_9_layer_call_fn while saving (showing 5 of 900). These functions will not be directly callable after loading.\n"
     ]
    }
   ],
   "source": [
    "### Create and save the predictor\n",
    "\n",
    "config_detail = f\"{model_name}_{score}_{run_id}\"\n",
    "predictor = HF2TFSeq2SeqExporter(model, tokenizers, BOS_IDS, beam_params, sampler_params,\n",
    "                                 bert_names, config_detail, lang, lang)\n",
    "predictor_dir = os.path.join(DIR_MODEL, f\"{model_name}_{score}\")\n",
    "tf.saved_model.save(predictor, export_dir=predictor_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QfcsSWswSdGV"
   },
   "source": [
    "## <b> 4. Inference <b/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.servitization import HF2TFSeq2SeqPipeline\n",
    "from utils.callback import print_seq2seq\n",
    "from utils.visualization import plot_attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Reload the pipeline to verify the result\n",
    "\n",
    "text_preprocessors = {'inp': preprocessors[lang], 'tar': preprocessors[lang]}\n",
    "pretrain_dir = DIR_MODELTORCH\n",
    "\n",
    "pipeline = HF2TFSeq2SeqPipeline(predictor_dir, pretrain_dir, text_preprocessors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b> Sentence <b/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"朋友買了一件衣料，綠色的底子帶白色方格，當她拿給我們看時，一位對圍棋十分感與趣的同學說：「啊，好像棋盤似的。」\",\n",
    "    \"「我看倒有點像稿紙。」我說。「真像一塊塊綠豆糕。」一位外號叫「大食客」的同學緊接著說。\",\n",
    "    \"我們不禁哄堂大笑，同樣的一件衣料，每個人卻有不同的感覺。那位朋友連忙把衣料用紙包好，她覺得衣料就是衣料，不是棋盤，也不是稿紙，更不是綠豆糕。\",\n",
    "    \"JoJo的奇妙冒險中出現了大量的超自然元素，也結合了真實世界的人物和事件。第一部的故事圍繞著一個只要沾上血就能將配戴者變成吸血鬼的石鬼面，而吸血鬼可以將人變成殭屍，吸血鬼和殭屍只能被太陽光或波紋氣功消滅，波紋是一種透過規律呼吸來產生能量的武術。在第二部中，出現了超古代生物柱之男，他們有著遠超過人類、吸血鬼和殭屍的力量以及壽命，但一樣不能曬到太陽光和被紫外線照射。此外、第二部還使用了納粹、人體實驗、賽博格等元素。\",\n",
    "    \"喬斯達家族有幾個共同特徵：頸部的左後方有星形的記號（第三部追加）、魁梧高大的身形、藍色或藍綠色的瞳孔、強烈的好奇心和正義感、愛好冒險的精神、專情且幾乎短命。\",    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = text_preprocessors['inp'](\"朋友買了3G/35G一件衣料，綠色的底子帶白色方格，當她拿給我們看時，一位對圍棋十分感與趣的同學說：「啊，好像棋盤似的。」\").numpy().decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'朋 友 買 了 ３ ｇ ／ ３ ５ ｇ 一 件 衣 料 ， 綠 色 的 底 子 帶 白 色 方 格 ， 當 她 拿 給 我 們 看 時 ， 一 位 對 圍 棋 十 分 感 與 趣 的 同 學 說 ： 「 啊 ， 好 像 棋 盤 似 的 。 」'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101,\n",
       " 3301,\n",
       " 1351,\n",
       " 6525,\n",
       " 749,\n",
       " 8031,\n",
       " 8057,\n",
       " 8027,\n",
       " 8031,\n",
       " 8033,\n",
       " 8057,\n",
       " 671,\n",
       " 816,\n",
       " 6132,\n",
       " 3160,\n",
       " 8024,\n",
       " 5199,\n",
       " 5682,\n",
       " 4638,\n",
       " 2419,\n",
       " 2094,\n",
       " 2380,\n",
       " 4635,\n",
       " 5682,\n",
       " 3175,\n",
       " 3419,\n",
       " 8024,\n",
       " 4534,\n",
       " 1961,\n",
       " 2897,\n",
       " 5183,\n",
       " 2769,\n",
       " 947,\n",
       " 4692,\n",
       " 3229,\n",
       " 8024,\n",
       " 671,\n",
       " 855,\n",
       " 2205,\n",
       " 1752,\n",
       " 3470,\n",
       " 1282,\n",
       " 1146,\n",
       " 2697,\n",
       " 5645,\n",
       " 6637,\n",
       " 4638,\n",
       " 1398,\n",
       " 2119,\n",
       " 6303,\n",
       " 8038,\n",
       " 519,\n",
       " 1557,\n",
       " 8024,\n",
       " 1962,\n",
       " 1008,\n",
       " 3470,\n",
       " 4676,\n",
       " 849,\n",
       " 4638,\n",
       " 511,\n",
       " 520,\n",
       " 102]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizers.inp.encode(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'ㄅ' in tokenizers.inp.vocab.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'ｓ' in [i.decode() for i in tokenizers.tar.vocab.numpy()] #tokenize('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:         : 朋友買了一件衣料，綠色的底子帶白色方格，當她拿給我們看時，一位對圍棋十分感與趣的同學說：「啊，好像棋盤似的。」\n",
      "Prediction     : ［ ｕ ｎ ｋ ］\n",
      "\n",
      "Input:         : 「我看倒有點像稿紙。」我說。「真像一塊塊綠豆糕。」一位外號叫「大食客」的同學緊接著說。\n",
      "Prediction     : 「 大 食 客 」 同 學 緊 接 著 說 ［ ｕ ｎ ｋ ］ 我 看 像 綠 豆 糕\n",
      "\n",
      "Input:         : 我們不禁哄堂大笑，同樣的一件衣料，每個人卻有不同的感覺。那位朋友連忙把衣料用紙包好，她覺得衣料就是衣料，不是棋盤，也不是稿紙，更不是綠豆糕。\n",
      "Prediction     : 如 何 用 紙 包 包 好 衣 料\n",
      "\n",
      "Input:         : JoJo的奇妙冒險中出現了大量的超自然元素，也結合了真實世界的人物和事件。第一部的故事圍繞著一個只要沾上血就能將配戴者變成吸血鬼的石鬼面，而吸血鬼可以將人變成殭屍，吸血鬼和殭屍只能被太陽光或波紋氣功消滅，波紋是一種透過規律呼吸來產生能量的武術。在第二部中，出現了超古代生物柱之男，他們有著遠超過人類、吸血鬼和殭屍的力量以及壽命，但一樣不能曬到太陽光和被紫外線照射。此外、第二部還使用了納粹、人體實驗、賽博格等元素。\n",
      "Prediction     : ［ ｕ ｎ ｋ ］ 的 奇 妙 冒 險\n",
      "\n",
      "Input:         : 喬斯達家族有幾個共同特徵：頸部的左後方有星形的記號（第三部追加）、魁梧高大的身形、藍色或藍綠色的瞳孔、強烈的好奇心和正義感、愛好冒險的精神、專情且幾乎短命。\n",
      "Prediction     : 喬 斯 達 家 族 的 ［ ｕ ｎ ｋ ］ 個 特 徵\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sentence in sentences:\n",
    "    target_text, target_tokens, attention_weights = pipeline(sentence, return_attention=True)\n",
    "    print_seq2seq(sentence, target_text, ground_truth=None)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:         : 朋友買了一件衣料，綠色的底子帶白色方格，當她拿給我們看時，一位對圍棋十分感與趣的同學說：「啊，好像棋盤似的。」\n",
      "Prediction     : 買 了 一 件 衣 料 , 好 像 棋 盤 似 白 色 方 格\n",
      "\n",
      "Input:         : 「我看倒有點像稿紙。」我說。「真像一塊塊綠豆糕。」一位外號叫「大食客」的同學緊接著說。\n",
      "Prediction     : 大 食 客 : 我 看 像 綠 豆 糕\n",
      "\n",
      "Input:         : 我們不禁哄堂大笑，同樣的一件衣料，每個人卻有不同的感覺。那位朋友連忙把衣料用紙包好，她覺得衣料就是衣料，不是棋盤，也不是稿紙，更不是綠豆糕。\n",
      "Prediction     : 一 件 衣 料 , 你 知 道 嗎 ?\n",
      "\n",
      "Input:         : JoJo的奇妙冒險中出現了大量的超自然元素，也結合了真實世界的人物和事件。第一部的故事圍繞著一個只要沾上血就能將配戴者變成吸血鬼的石鬼面，而吸血鬼可以將人變成殭屍，吸血鬼和殭屍只能被太陽光或波紋氣功消滅，波紋是一種透過規律呼吸來產生能量的武術。在第二部中，出現了超古代生物柱之男，他們有著遠超過人類、吸血鬼和殭屍的力量以及壽命，但一樣不能曬到太陽光和被紫外線照射。此外、第二部還使用了納粹、人體實驗、賽博格等元素。\n",
      "Prediction     : 奇 妙 冒 險\n",
      "\n",
      "Input:         : 喬斯達家族有幾個共同特徵：頸部的左後方有星形的記號（第三部追加）、魁梧高大的身形、藍色或藍綠色的瞳孔、強烈的好奇心和正義感、愛好冒險的精神、專情且幾乎短命。\n",
      "Prediction     : 喬 斯 達 家 族 的 幾 個 共 同 特 徵\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "last_runtime": {
    "build_target": "//learning/deepmind/public/tools/ml_python:ml_notebook",
    "kind": "private"
   },
   "name": "transformer.ipynb",
   "provenance": [
    {
     "file_id": "1fpiHY_g7b1-bs_sSRWcbiw9qv4eDU4QZ",
     "timestamp": 1628275335747
    },
    {
     "file_id": "https://github.com/tensorflow/text/blob/master/docs/tutorials/transformer.ipynb",
     "timestamp": 1628273726995
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
